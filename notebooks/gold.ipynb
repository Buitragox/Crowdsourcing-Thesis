{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buitragox/Crowdsourcing-Thesis/blob/main/notebooks/gold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gold Standard Training\n",
        "\n",
        "Base model with gold standard dataset\n",
        "\n",
        "Two models are trained\n",
        "- Categorical crossentropy\n",
        "- Focal loss\n",
        "\n",
        "Dataset with oversampling was not used."
      ],
      "metadata": {
        "id": "ZdJiy4i4D2Eh"
      },
      "id": "ZdJiy4i4D2Eh"
    },
    {
      "cell_type": "markdown",
      "id": "7754b6d0-7e28-45b9-be66-092bd6ea7a2d",
      "metadata": {
        "id": "7754b6d0-7e28-45b9-be66-092bd6ea7a2d"
      },
      "source": [
        "Dataset before feature extraction: https://drive.google.com/drive/folders/1yWT1aaQLiZAkAomtAdFlqlVWnRkhNrCu\n",
        "\n",
        "The images are located in three separate folders: 1, 2 and 3. This indicates the image's class.\n",
        "\n",
        "The labels were encoded using one-hot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4521a4-8423-403c-a4f3-8127ccefa3fa",
      "metadata": {
        "id": "0e4521a4-8423-403c-a4f3-8127ccefa3fa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ss-xy7pM4__-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss-xy7pM4__-",
        "outputId": "e335ad2b-6a46-400e-c4ac-ec0b5befa01f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# If using google drive in google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z6SgW-OX5DWD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6SgW-OX5DWD",
        "outputId": "c6e61a17-cbd3-46fe-8236-3b4755c579cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-29 00:58:10--  https://raw.githubusercontent.com/Buitragox/Crowdsourcing-Thesis/main/BCSS/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5405 (5.3K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   5.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-29 00:58:10 (40.2 MB/s) - ‘utils.py’ saved [5405/5405]\n",
            "\n",
            "--2024-05-29 00:58:10--  https://raw.githubusercontent.com/Buitragox/Crowdsourcing-Thesis/main/BCSS/grid_search.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5486 (5.4K) [text/plain]\n",
            "Saving to: ‘grid_search.py’\n",
            "\n",
            "grid_search.py      100%[===================>]   5.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-29 00:58:11 (41.2 MB/s) - ‘grid_search.py’ saved [5486/5486]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Files with commonly used functions and utilities\n",
        "!wget --no-check-certificate 'https://raw.githubusercontent.com/Buitragox/Crowdsourcing-Thesis/main/utils.py' -O utils.py\n",
        "!wget --no-check-certificate 'https://raw.githubusercontent.com/Buitragox/Crowdsourcing-Thesis/main/grid_search.py' -O grid_search.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eKlufnLM5B8X",
      "metadata": {
        "id": "eKlufnLM5B8X"
      },
      "outputs": [],
      "source": [
        "from utils import load_gold_data\n",
        "from grid_search import grid_search, show_results, save_to_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cKK5UXTT5hRW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKK5UXTT5hRW",
        "outputId": "a9ea4ecd-4aa8-43ef-9ef6-55955df10ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-29 00:58:11--  https://github.com/Buitragox/Crowdsourcing-Thesis/raw/main/BCSS/pkl/train_crowdsourced_labels.pkl\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Buitragox/Crowdsourcing-Thesis/main/BCSS/pkl/train_crowdsourced_labels.pkl [following]\n",
            "--2024-05-29 00:58:11--  https://raw.githubusercontent.com/Buitragox/Crowdsourcing-Thesis/main/BCSS/pkl/train_crowdsourced_labels.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10426477 (9.9M) [application/octet-stream]\n",
            "Saving to: ‘train_crowdsourced_labels.pkl’\n",
            "\n",
            "train_crowdsourced_ 100%[===================>]   9.94M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-05-29 00:58:12 (69.2 MB/s) - ‘train_crowdsourced_labels.pkl’ saved [10426477/10426477]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# pkl file with crowdsourced labels\n",
        "!wget --no-check-certificate 'https://github.com/Buitragox/Crowdsourcing-Thesis/raw/main/data/pkl/train_crowdsourced_labels.pkl' -O train_crowdsourced_labels.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1_V1Eibc5m3g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_V1Eibc5m3g",
        "outputId": "e9fb0412-c2e6-491d-c153-70379c4cb49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1XeVC0FOmv_V8jY31JP73yXqa4q27EWJS\n",
            "From (redirected): https://drive.google.com/uc?id=1XeVC0FOmv_V8jY31JP73yXqa4q27EWJS&confirm=t&uuid=802eaef8-902d-42e4-b96f-7b4cfa021847\n",
            "To: /content/TrainTestNpyInt.zip\n",
            "100% 96.7M/96.7M [00:02<00:00, 44.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download TrainTestNpyInt.zip from google drive\n",
        "!pip install gdown\n",
        "!gdown 1XeVC0FOmv_V8jY31JP73yXqa4q27EWJS -O TrainTestNpyInt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-2ep9jVT50K2",
      "metadata": {
        "id": "-2ep9jVT50K2"
      },
      "outputs": [],
      "source": [
        "# Extract zip file\n",
        "with zipfile.ZipFile(\"./TrainTestNpyInt.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./TrainTestNpyInt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aNX4eJiR522K",
      "metadata": {
        "id": "aNX4eJiR522K"
      },
      "outputs": [],
      "source": [
        "pkl_path = \"./train_crowdsourced_labels.pkl\"\n",
        "\n",
        "# Path for the extracted zip files\n",
        "data_path = \"./TrainTestNpyInt\"\n",
        "\n",
        "# Path to save the results\n",
        "json_path = \"./drive/MyDrive/Experiment results/gold\"\n",
        "K = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6b88b45-5b17-4894-a492-19dbb8351c81",
      "metadata": {
        "id": "c6b88b45-5b17-4894-a492-19dbb8351c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625d3a08-6d8b-4aa3-e65d-a18440fe947a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"VGG16_GOLD\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74115 (289.51 KB)\n",
            "Trainable params: 74115 (289.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_model():\n",
        "    \"\"\"Base arquitecture for training all models\"\"\"\n",
        "    input_layer = Input(shape=(512, ))\n",
        "\n",
        "    model = Dense(128, activation='relu')(input_layer)\n",
        "    model = Dropout(0.25)(model)\n",
        "    model = Dense(64, activation='relu')(model)\n",
        "    model = Dropout(0.25)(model)\n",
        "\n",
        "    model = Dense(K, activation=\"softmax\")(model)\n",
        "\n",
        "    model = Model(input_layer, model, name=\"VGG16_GOLD\")\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "build_model().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gDt1q0AO6kQA",
      "metadata": {
        "id": "gDt1q0AO6kQA"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, X_test, Y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    report = classification_report(np.argmax(Y_test, axis=1), y_pred, output_dict=True)\n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5a2963-8afc-414e-9c4d-db8b7500465b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee5a2963-8afc-414e-9c4d-db8b7500465b",
        "outputId": "e9bfdaa5-df5c-4b6e-a371-c207a931d95d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run #1\n",
            "Epoch 1/10\n",
            "7525/7525 [==============================] - 35s 4ms/step - loss: 0.4848 - accuracy: 0.8113 - val_loss: 0.3932 - val_accuracy: 0.8429\n",
            "Epoch 2/10\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.4070 - accuracy: 0.8404 - val_loss: 0.3809 - val_accuracy: 0.8527\n",
            "Epoch 3/10\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.3905 - accuracy: 0.8468 - val_loss: 0.3537 - val_accuracy: 0.8586\n",
            "Epoch 4/10\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.3752 - accuracy: 0.8503 - val_loss: 0.3504 - val_accuracy: 0.8572\n",
            "Epoch 5/10\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.3688 - accuracy: 0.8543 - val_loss: 0.3449 - val_accuracy: 0.8636\n",
            "Epoch 6/10\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.3602 - accuracy: 0.8576 - val_loss: 0.3449 - val_accuracy: 0.8623\n",
            "Epoch 7/10\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.3558 - accuracy: 0.8580 - val_loss: 0.3558 - val_accuracy: 0.8597\n",
            "Epoch 8/10\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.3490 - accuracy: 0.8611 - val_loss: 0.3502 - val_accuracy: 0.8625\n",
            "Epoch 9/10\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.3453 - accuracy: 0.8642 - val_loss: 0.3410 - val_accuracy: 0.8650\n",
            "Epoch 10/10\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.3443 - accuracy: 0.8631 - val_loss: 0.3382 - val_accuracy: 0.8631\n",
            "137/137 [==============================] - 0s 1ms/step\n",
            "Run #2\n",
            "Epoch 1/10\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.4753 - accuracy: 0.8138 - val_loss: 0.3861 - val_accuracy: 0.8448\n",
            "Epoch 2/10\n",
            "7525/7525 [==============================] - 32s 4ms/step - loss: 0.4097 - accuracy: 0.8384 - val_loss: 0.3865 - val_accuracy: 0.8500\n",
            "Epoch 3/10\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.3892 - accuracy: 0.8448 - val_loss: 0.3595 - val_accuracy: 0.8543\n",
            "Epoch 4/10\n",
            "7525/7525 [==============================] - 32s 4ms/step - loss: 0.3774 - accuracy: 0.8508 - val_loss: 0.3540 - val_accuracy: 0.8597\n",
            "Epoch 5/10\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.3675 - accuracy: 0.8555 - val_loss: 0.3544 - val_accuracy: 0.8555\n",
            "Epoch 6/10\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.3616 - accuracy: 0.8563 - val_loss: 0.3531 - val_accuracy: 0.8573\n",
            "Epoch 7/10\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.3562 - accuracy: 0.8593 - val_loss: 0.3413 - val_accuracy: 0.8601\n",
            "Epoch 8/10\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.3482 - accuracy: 0.8618 - val_loss: 0.4223 - val_accuracy: 0.8626\n",
            "Epoch 9/10\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.3436 - accuracy: 0.8616 - val_loss: 0.3298 - val_accuracy: 0.8664\n",
            "Epoch 10/10\n",
            "7525/7525 [==============================] - 32s 4ms/step - loss: 0.3394 - accuracy: 0.8647 - val_loss: 0.3359 - val_accuracy: 0.8648\n",
            "137/137 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "X_train, labels, X_test, Y_test = load_gold_data(data_path, pkl_path)\n",
        "\n",
        "history, report = grid_search(X_train, labels, X_test, Y_test, build_model, evaluate, repeat=2, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TgSFtwKJ_nyI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgSFtwKJ_nyI",
        "outputId": "172b1c0a-7568-4169-c7f7-46318b27b32b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "parameters = {}\n",
            "\tmean f1 scores: [0.8686367080715145, 0.7488557017009703, 0.7348605040005178]\n",
            "\tstd f1 scores: [0.008380542902330756, 0.0019612917630819626, 0.0030472575292909143]\n",
            "\tmean accuracy: 0.8203483043079743\n",
            "\tstd accuracy: 0.007103574702108206\n"
          ]
        }
      ],
      "source": [
        "show_results(history, report, K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kp4ooQk5GVtV",
      "metadata": {
        "id": "Kp4ooQk5GVtV"
      },
      "outputs": [],
      "source": [
        "save_to_json(history, report, json_path+'/history_gold_int.json', json_path+'/report_gold_int.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CNN3wiTFf2wh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNN3wiTFf2wh",
        "outputId": "be918fa4-672d-4a92-ad74-ff1b1cb9f651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'0': {'precision': 0.8758799555390886, 'recall': 0.8781575037147102, 'f1-score': 0.8770172509738453, 'support': 2692}, '1': {'precision': 0.7340255591054313, 'recall': 0.7683946488294314, 'f1-score': 0.7508169934640523, 'support': 1196}, '2': {'precision': 0.7941888619854721, 'recall': 0.6890756302521008, 'f1-score': 0.7379077615298087, 'support': 476}, 'accuracy': 0.8274518790100825, 'macro avg': {'precision': 0.8013647922099972, 'recall': 0.7785425942654142, 'f1-score': 0.7885806686559022, 'support': 4364}, 'weighted avg': {'precision': 0.8280928751847862, 'recall': 0.8274518790100825, 'f1-score': 0.8272574835684663, 'support': 4364}}\n"
          ]
        }
      ],
      "source": [
        "rep = report[0][\"reports\"][0]\n",
        "print(rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VyrZcGpFbclr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "VyrZcGpFbclr",
        "outputId": "4ca9fcbf-fee8-4ecd-8aa6-06b306f96d5b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 960x640 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = history[0][\"histories\"][0]\n",
        "plt.figure(figsize=(6, 4), dpi=160)\n",
        "plt.plot(run[\"loss\"], label=\"train\")\n",
        "plt.plot(run[\"val_loss\"], label=\"validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8AZobyDeISj3",
      "metadata": {
        "id": "8AZobyDeISj3"
      },
      "source": [
        "## Over Sampling\n",
        "\n",
        "NOTE: Oversampling was not used in final analisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uJFs7bKpIq_L",
      "metadata": {
        "id": "uJFs7bKpIq_L"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gKru6GBIIygQ",
      "metadata": {
        "id": "gKru6GBIIygQ"
      },
      "outputs": [],
      "source": [
        "X_train, labels, X_test, Y_test = load_gold_data(data_path, pkl_path)\n",
        "\n",
        "over_sampler = RandomOverSampler(random_state=42)\n",
        "X_train_os, labels_os = over_sampler.fit_resample(X_train, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pAzLruJWLU0F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAzLruJWLU0F",
        "outputId": "63b962cc-07b4-4a3d-e395-bc74a15a4b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run #1\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.4705 - accuracy: 0.8134 - val_loss: 0.5311 - val_accuracy: 0.7582\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.4097 - accuracy: 0.8360 - val_loss: 0.5724 - val_accuracy: 0.7536\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3927 - accuracy: 0.8427 - val_loss: 0.5839 - val_accuracy: 0.7216\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3815 - accuracy: 0.8470 - val_loss: 0.5166 - val_accuracy: 0.7695\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3728 - accuracy: 0.8522 - val_loss: 0.4435 - val_accuracy: 0.8223\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 36s 3ms/step - loss: 0.3648 - accuracy: 0.8548 - val_loss: 0.5062 - val_accuracy: 0.7496\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3585 - accuracy: 0.8570 - val_loss: 0.5326 - val_accuracy: 0.7802\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 36s 3ms/step - loss: 0.3566 - accuracy: 0.8582 - val_loss: 0.3593 - val_accuracy: 0.8472\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3509 - accuracy: 0.8590 - val_loss: 0.4967 - val_accuracy: 0.7646\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3463 - accuracy: 0.8621 - val_loss: 0.5154 - val_accuracy: 0.7667\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 36s 3ms/step - loss: 0.3437 - accuracy: 0.8630 - val_loss: 0.3324 - val_accuracy: 0.8588\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3405 - accuracy: 0.8642 - val_loss: 0.3874 - val_accuracy: 0.8181\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 43s 4ms/step - loss: 0.3358 - accuracy: 0.8665 - val_loss: 0.4856 - val_accuracy: 0.7771\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3345 - accuracy: 0.8663 - val_loss: 0.3754 - val_accuracy: 0.8318\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3300 - accuracy: 0.8683 - val_loss: 0.3875 - val_accuracy: 0.8391\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3272 - accuracy: 0.8703 - val_loss: 0.4065 - val_accuracy: 0.8600\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3277 - accuracy: 0.8699 - val_loss: 0.3834 - val_accuracy: 0.8459\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 36s 3ms/step - loss: 0.3241 - accuracy: 0.8712 - val_loss: 0.4572 - val_accuracy: 0.8056\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3243 - accuracy: 0.8696 - val_loss: 0.4481 - val_accuracy: 0.8003\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3211 - accuracy: 0.8717 - val_loss: 0.2520 - val_accuracy: 0.9117\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #2\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.4701 - accuracy: 0.8145 - val_loss: 0.3263 - val_accuracy: 0.8600\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 43s 4ms/step - loss: 0.4065 - accuracy: 0.8381 - val_loss: 0.5687 - val_accuracy: 0.7655\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3879 - accuracy: 0.8449 - val_loss: 0.4249 - val_accuracy: 0.8051\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3751 - accuracy: 0.8490 - val_loss: 0.5231 - val_accuracy: 0.8011\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3671 - accuracy: 0.8522 - val_loss: 0.5061 - val_accuracy: 0.7544\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3608 - accuracy: 0.8558 - val_loss: 0.5468 - val_accuracy: 0.7449\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3546 - accuracy: 0.8576 - val_loss: 0.3754 - val_accuracy: 0.8627\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3485 - accuracy: 0.8607 - val_loss: 0.3784 - val_accuracy: 0.8357\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3449 - accuracy: 0.8627 - val_loss: 0.3524 - val_accuracy: 0.8450\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 44s 4ms/step - loss: 0.3406 - accuracy: 0.8639 - val_loss: 0.3455 - val_accuracy: 0.8542\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3341 - accuracy: 0.8659 - val_loss: 0.2934 - val_accuracy: 0.8969\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 44s 4ms/step - loss: 0.3315 - accuracy: 0.8685 - val_loss: 0.3721 - val_accuracy: 0.8473\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3293 - accuracy: 0.8689 - val_loss: 0.4122 - val_accuracy: 0.8086\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3263 - accuracy: 0.8700 - val_loss: 0.3421 - val_accuracy: 0.8583\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3234 - accuracy: 0.8725 - val_loss: 0.5987 - val_accuracy: 0.7531\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3214 - accuracy: 0.8715 - val_loss: 0.3703 - val_accuracy: 0.8441\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3182 - accuracy: 0.8734 - val_loss: 0.2866 - val_accuracy: 0.8974\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3155 - accuracy: 0.8743 - val_loss: 0.2970 - val_accuracy: 0.8740\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3143 - accuracy: 0.8752 - val_loss: 0.3590 - val_accuracy: 0.8319\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3099 - accuracy: 0.8756 - val_loss: 0.2844 - val_accuracy: 0.8895\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #3\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.4688 - accuracy: 0.8143 - val_loss: 0.4925 - val_accuracy: 0.7928\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.4069 - accuracy: 0.8383 - val_loss: 0.6294 - val_accuracy: 0.7262\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3887 - accuracy: 0.8422 - val_loss: 0.4460 - val_accuracy: 0.7934\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3775 - accuracy: 0.8492 - val_loss: 0.3578 - val_accuracy: 0.8387\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3689 - accuracy: 0.8525 - val_loss: 0.4949 - val_accuracy: 0.7787\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3625 - accuracy: 0.8558 - val_loss: 0.4313 - val_accuracy: 0.8138\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3535 - accuracy: 0.8594 - val_loss: 0.4604 - val_accuracy: 0.8090\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3493 - accuracy: 0.8618 - val_loss: 0.3760 - val_accuracy: 0.8345\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3434 - accuracy: 0.8644 - val_loss: 0.6009 - val_accuracy: 0.7433\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3406 - accuracy: 0.8647 - val_loss: 0.4114 - val_accuracy: 0.8278\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3345 - accuracy: 0.8675 - val_loss: 0.5059 - val_accuracy: 0.8010\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3324 - accuracy: 0.8675 - val_loss: 0.3906 - val_accuracy: 0.8373\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 36s 3ms/step - loss: 0.3266 - accuracy: 0.8695 - val_loss: 0.3978 - val_accuracy: 0.8309\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 36s 3ms/step - loss: 0.3263 - accuracy: 0.8703 - val_loss: 0.3569 - val_accuracy: 0.8451\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3230 - accuracy: 0.8712 - val_loss: 0.3438 - val_accuracy: 0.8498\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3202 - accuracy: 0.8719 - val_loss: 0.4171 - val_accuracy: 0.8368\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3163 - accuracy: 0.8750 - val_loss: 0.3949 - val_accuracy: 0.8476\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3170 - accuracy: 0.8741 - val_loss: 0.4486 - val_accuracy: 0.8018\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3131 - accuracy: 0.8754 - val_loss: 0.4210 - val_accuracy: 0.8387\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3101 - accuracy: 0.8774 - val_loss: 0.4079 - val_accuracy: 0.7851\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #4\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.4722 - accuracy: 0.8139 - val_loss: 0.4507 - val_accuracy: 0.7801\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 43s 4ms/step - loss: 0.4070 - accuracy: 0.8370 - val_loss: 0.5452 - val_accuracy: 0.7576\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3896 - accuracy: 0.8448 - val_loss: 0.3373 - val_accuracy: 0.8421\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3785 - accuracy: 0.8499 - val_loss: 0.3694 - val_accuracy: 0.8413\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3668 - accuracy: 0.8542 - val_loss: 0.4699 - val_accuracy: 0.7754\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3609 - accuracy: 0.8581 - val_loss: 0.4357 - val_accuracy: 0.8087\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3538 - accuracy: 0.8593 - val_loss: 0.3525 - val_accuracy: 0.8641\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3479 - accuracy: 0.8618 - val_loss: 0.3823 - val_accuracy: 0.8459\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3432 - accuracy: 0.8630 - val_loss: 0.2924 - val_accuracy: 0.8846\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3390 - accuracy: 0.8651 - val_loss: 0.3077 - val_accuracy: 0.8761\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 36s 3ms/step - loss: 0.3350 - accuracy: 0.8680 - val_loss: 0.4469 - val_accuracy: 0.8154\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3327 - accuracy: 0.8696 - val_loss: 0.4662 - val_accuracy: 0.8030\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 44s 4ms/step - loss: 0.3265 - accuracy: 0.8697 - val_loss: 0.2564 - val_accuracy: 0.9024\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3251 - accuracy: 0.8721 - val_loss: 0.4185 - val_accuracy: 0.8073\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3250 - accuracy: 0.8714 - val_loss: 0.3736 - val_accuracy: 0.8485\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3168 - accuracy: 0.8759 - val_loss: 0.5045 - val_accuracy: 0.7644\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3143 - accuracy: 0.8761 - val_loss: 0.4126 - val_accuracy: 0.8160\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3141 - accuracy: 0.8760 - val_loss: 0.5076 - val_accuracy: 0.7821\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3107 - accuracy: 0.8770 - val_loss: 0.2821 - val_accuracy: 0.8872\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3084 - accuracy: 0.8794 - val_loss: 0.3259 - val_accuracy: 0.8677\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #5\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.4750 - accuracy: 0.8120 - val_loss: 0.3815 - val_accuracy: 0.8518\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.4112 - accuracy: 0.8350 - val_loss: 0.5027 - val_accuracy: 0.7749\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3918 - accuracy: 0.8439 - val_loss: 0.4954 - val_accuracy: 0.7597\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3823 - accuracy: 0.8483 - val_loss: 0.5722 - val_accuracy: 0.7516\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3743 - accuracy: 0.8510 - val_loss: 0.6518 - val_accuracy: 0.7027\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3651 - accuracy: 0.8551 - val_loss: 0.4882 - val_accuracy: 0.7496\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3586 - accuracy: 0.8573 - val_loss: 0.5764 - val_accuracy: 0.7256\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3532 - accuracy: 0.8598 - val_loss: 0.4282 - val_accuracy: 0.8399\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3487 - accuracy: 0.8620 - val_loss: 0.4259 - val_accuracy: 0.8115\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3444 - accuracy: 0.8633 - val_loss: 0.4457 - val_accuracy: 0.8184\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3408 - accuracy: 0.8652 - val_loss: 0.3983 - val_accuracy: 0.8373\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3378 - accuracy: 0.8665 - val_loss: 0.4833 - val_accuracy: 0.7862\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3368 - accuracy: 0.8661 - val_loss: 0.4260 - val_accuracy: 0.8328\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3311 - accuracy: 0.8694 - val_loss: 0.3679 - val_accuracy: 0.8502\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3282 - accuracy: 0.8700 - val_loss: 0.3381 - val_accuracy: 0.8452\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3252 - accuracy: 0.8697 - val_loss: 0.3624 - val_accuracy: 0.8418\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3241 - accuracy: 0.8716 - val_loss: 0.3904 - val_accuracy: 0.8038\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3210 - accuracy: 0.8715 - val_loss: 0.4754 - val_accuracy: 0.7974\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 44s 4ms/step - loss: 0.3203 - accuracy: 0.8726 - val_loss: 0.3492 - val_accuracy: 0.8435\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3179 - accuracy: 0.8731 - val_loss: 0.3825 - val_accuracy: 0.8183\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #6\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.4675 - accuracy: 0.8137 - val_loss: 0.5336 - val_accuracy: 0.7514\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.4057 - accuracy: 0.8383 - val_loss: 0.6367 - val_accuracy: 0.6986\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3880 - accuracy: 0.8459 - val_loss: 0.5668 - val_accuracy: 0.7391\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3755 - accuracy: 0.8493 - val_loss: 0.3909 - val_accuracy: 0.8247\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3655 - accuracy: 0.8540 - val_loss: 0.2447 - val_accuracy: 0.9050\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3596 - accuracy: 0.8566 - val_loss: 0.4015 - val_accuracy: 0.8285\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3522 - accuracy: 0.8598 - val_loss: 0.5439 - val_accuracy: 0.7301\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3475 - accuracy: 0.8610 - val_loss: 0.4306 - val_accuracy: 0.8192\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3419 - accuracy: 0.8639 - val_loss: 0.3578 - val_accuracy: 0.8468\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3381 - accuracy: 0.8663 - val_loss: 0.3258 - val_accuracy: 0.8802\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3345 - accuracy: 0.8684 - val_loss: 0.4528 - val_accuracy: 0.8250\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 44s 4ms/step - loss: 0.3308 - accuracy: 0.8695 - val_loss: 0.2642 - val_accuracy: 0.8972\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3279 - accuracy: 0.8710 - val_loss: 0.4269 - val_accuracy: 0.8088\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3201 - accuracy: 0.8726 - val_loss: 0.3635 - val_accuracy: 0.8666\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3215 - accuracy: 0.8724 - val_loss: 0.3497 - val_accuracy: 0.8551\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3190 - accuracy: 0.8736 - val_loss: 0.3611 - val_accuracy: 0.8362\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 37s 3ms/step - loss: 0.3137 - accuracy: 0.8754 - val_loss: 0.3004 - val_accuracy: 0.8625\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3135 - accuracy: 0.8773 - val_loss: 0.2895 - val_accuracy: 0.8810\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3095 - accuracy: 0.8782 - val_loss: 0.3161 - val_accuracy: 0.8640\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3074 - accuracy: 0.8779 - val_loss: 0.3817 - val_accuracy: 0.8263\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #7\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.4774 - accuracy: 0.8130 - val_loss: 0.7018 - val_accuracy: 0.6528\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.4108 - accuracy: 0.8378 - val_loss: 0.6062 - val_accuracy: 0.7600\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 46s 4ms/step - loss: 0.3931 - accuracy: 0.8434 - val_loss: 0.5058 - val_accuracy: 0.7320\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3792 - accuracy: 0.8484 - val_loss: 0.3870 - val_accuracy: 0.8490\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3680 - accuracy: 0.8530 - val_loss: 0.4177 - val_accuracy: 0.8301\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3652 - accuracy: 0.8555 - val_loss: 0.3276 - val_accuracy: 0.8548\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3552 - accuracy: 0.8589 - val_loss: 0.3848 - val_accuracy: 0.8487\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3514 - accuracy: 0.8605 - val_loss: 0.4658 - val_accuracy: 0.8099\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3489 - accuracy: 0.8617 - val_loss: 0.4633 - val_accuracy: 0.8073\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3440 - accuracy: 0.8621 - val_loss: 0.3148 - val_accuracy: 0.8698\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3385 - accuracy: 0.8632 - val_loss: 0.5291 - val_accuracy: 0.7572\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3363 - accuracy: 0.8652 - val_loss: 0.4289 - val_accuracy: 0.8056\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3324 - accuracy: 0.8668 - val_loss: 0.5050 - val_accuracy: 0.7679\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3292 - accuracy: 0.8693 - val_loss: 0.5599 - val_accuracy: 0.7555\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3249 - accuracy: 0.8695 - val_loss: 0.2747 - val_accuracy: 0.8944\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3242 - accuracy: 0.8694 - val_loss: 0.4358 - val_accuracy: 0.8222\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3219 - accuracy: 0.8717 - val_loss: 0.2663 - val_accuracy: 0.9083\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3209 - accuracy: 0.8720 - val_loss: 0.4415 - val_accuracy: 0.8033\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3174 - accuracy: 0.8726 - val_loss: 0.3432 - val_accuracy: 0.8606\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3130 - accuracy: 0.8750 - val_loss: 0.3435 - val_accuracy: 0.8714\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #8\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.4722 - accuracy: 0.8141 - val_loss: 0.4903 - val_accuracy: 0.7943\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.4073 - accuracy: 0.8376 - val_loss: 0.4495 - val_accuracy: 0.8020\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3908 - accuracy: 0.8435 - val_loss: 0.3242 - val_accuracy: 0.8809\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3767 - accuracy: 0.8493 - val_loss: 0.5162 - val_accuracy: 0.7696\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3709 - accuracy: 0.8538 - val_loss: 0.4429 - val_accuracy: 0.8101\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3623 - accuracy: 0.8550 - val_loss: 0.4735 - val_accuracy: 0.7763\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3545 - accuracy: 0.8593 - val_loss: 0.4232 - val_accuracy: 0.8188\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3478 - accuracy: 0.8623 - val_loss: 0.3755 - val_accuracy: 0.8211\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3421 - accuracy: 0.8637 - val_loss: 0.4843 - val_accuracy: 0.7583\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3402 - accuracy: 0.8649 - val_loss: 0.3496 - val_accuracy: 0.8543\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 46s 4ms/step - loss: 0.3360 - accuracy: 0.8651 - val_loss: 0.3015 - val_accuracy: 0.8864\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3343 - accuracy: 0.8674 - val_loss: 0.4375 - val_accuracy: 0.8015\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3303 - accuracy: 0.8691 - val_loss: 0.4296 - val_accuracy: 0.8062\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3242 - accuracy: 0.8704 - val_loss: 0.2531 - val_accuracy: 0.9084\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3215 - accuracy: 0.8718 - val_loss: 0.4177 - val_accuracy: 0.8226\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3185 - accuracy: 0.8730 - val_loss: 0.3454 - val_accuracy: 0.8389\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3175 - accuracy: 0.8737 - val_loss: 0.2839 - val_accuracy: 0.8789\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3136 - accuracy: 0.8750 - val_loss: 0.4667 - val_accuracy: 0.8048\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3104 - accuracy: 0.8775 - val_loss: 0.3845 - val_accuracy: 0.8492\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3086 - accuracy: 0.8779 - val_loss: 0.3391 - val_accuracy: 0.8426\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #9\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.4691 - accuracy: 0.8146 - val_loss: 0.3739 - val_accuracy: 0.8565\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 45s 4ms/step - loss: 0.4052 - accuracy: 0.8390 - val_loss: 0.7485 - val_accuracy: 0.6486\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3892 - accuracy: 0.8445 - val_loss: 0.4956 - val_accuracy: 0.7848\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3755 - accuracy: 0.8513 - val_loss: 0.3896 - val_accuracy: 0.8191\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3687 - accuracy: 0.8542 - val_loss: 0.3618 - val_accuracy: 0.8441\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3605 - accuracy: 0.8580 - val_loss: 0.5322 - val_accuracy: 0.7691\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 46s 4ms/step - loss: 0.3541 - accuracy: 0.8585 - val_loss: 0.4553 - val_accuracy: 0.7807\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3471 - accuracy: 0.8625 - val_loss: 0.3715 - val_accuracy: 0.8447\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3459 - accuracy: 0.8623 - val_loss: 0.4914 - val_accuracy: 0.7988\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3393 - accuracy: 0.8656 - val_loss: 0.4847 - val_accuracy: 0.7933\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3366 - accuracy: 0.8667 - val_loss: 0.3336 - val_accuracy: 0.8553\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 38s 3ms/step - loss: 0.3306 - accuracy: 0.8686 - val_loss: 0.5059 - val_accuracy: 0.7328\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3300 - accuracy: 0.8707 - val_loss: 0.4343 - val_accuracy: 0.8137\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3268 - accuracy: 0.8709 - val_loss: 0.3347 - val_accuracy: 0.8640\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 39s 4ms/step - loss: 0.3226 - accuracy: 0.8722 - val_loss: 0.3695 - val_accuracy: 0.8585\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 39s 3ms/step - loss: 0.3194 - accuracy: 0.8732 - val_loss: 0.3249 - val_accuracy: 0.8672\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3163 - accuracy: 0.8744 - val_loss: 0.4090 - val_accuracy: 0.8325\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3124 - accuracy: 0.8756 - val_loss: 0.4784 - val_accuracy: 0.7978\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3108 - accuracy: 0.8777 - val_loss: 0.4011 - val_accuracy: 0.8284\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3083 - accuracy: 0.8774 - val_loss: 0.3611 - val_accuracy: 0.8441\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #10\n",
            "Epoch 1/20\n",
            "11178/11178 [==============================] - 43s 4ms/step - loss: 0.4740 - accuracy: 0.8138 - val_loss: 0.4741 - val_accuracy: 0.7948\n",
            "Epoch 2/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.4042 - accuracy: 0.8389 - val_loss: 0.4805 - val_accuracy: 0.7912\n",
            "Epoch 3/20\n",
            "11178/11178 [==============================] - 43s 4ms/step - loss: 0.3858 - accuracy: 0.8462 - val_loss: 0.5816 - val_accuracy: 0.7511\n",
            "Epoch 4/20\n",
            "11178/11178 [==============================] - 40s 4ms/step - loss: 0.3740 - accuracy: 0.8504 - val_loss: 0.4283 - val_accuracy: 0.8038\n",
            "Epoch 5/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3661 - accuracy: 0.8547 - val_loss: 0.4242 - val_accuracy: 0.8329\n",
            "Epoch 6/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3572 - accuracy: 0.8581 - val_loss: 0.3820 - val_accuracy: 0.8410\n",
            "Epoch 7/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3496 - accuracy: 0.8617 - val_loss: 0.6769 - val_accuracy: 0.7029\n",
            "Epoch 8/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3447 - accuracy: 0.8638 - val_loss: 0.3834 - val_accuracy: 0.8217\n",
            "Epoch 9/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3395 - accuracy: 0.8642 - val_loss: 0.3167 - val_accuracy: 0.8771\n",
            "Epoch 10/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3355 - accuracy: 0.8676 - val_loss: 0.3461 - val_accuracy: 0.8451\n",
            "Epoch 11/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3290 - accuracy: 0.8690 - val_loss: 0.4255 - val_accuracy: 0.7937\n",
            "Epoch 12/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3250 - accuracy: 0.8695 - val_loss: 0.3928 - val_accuracy: 0.8194\n",
            "Epoch 13/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3229 - accuracy: 0.8717 - val_loss: 0.3800 - val_accuracy: 0.8585\n",
            "Epoch 14/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3217 - accuracy: 0.8728 - val_loss: 0.4885 - val_accuracy: 0.7863\n",
            "Epoch 15/20\n",
            "11178/11178 [==============================] - 49s 4ms/step - loss: 0.3189 - accuracy: 0.8735 - val_loss: 0.3660 - val_accuracy: 0.8616\n",
            "Epoch 16/20\n",
            "11178/11178 [==============================] - 43s 4ms/step - loss: 0.3153 - accuracy: 0.8745 - val_loss: 0.2876 - val_accuracy: 0.8937\n",
            "Epoch 17/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3124 - accuracy: 0.8755 - val_loss: 0.4939 - val_accuracy: 0.7710\n",
            "Epoch 18/20\n",
            "11178/11178 [==============================] - 41s 4ms/step - loss: 0.3100 - accuracy: 0.8783 - val_loss: 0.2643 - val_accuracy: 0.9037\n",
            "Epoch 19/20\n",
            "11178/11178 [==============================] - 42s 4ms/step - loss: 0.3079 - accuracy: 0.8777 - val_loss: 0.2969 - val_accuracy: 0.8710\n",
            "Epoch 20/20\n",
            "11178/11178 [==============================] - 43s 4ms/step - loss: 0.3047 - accuracy: 0.8791 - val_loss: 0.3396 - val_accuracy: 0.8368\n",
            "137/137 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "history, report = grid_search(X_train_os, labels_os, X_test, Y_test, build_model, evaluate, repeat=10, epochs=20, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aVQIwDUuLeXA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVQIwDUuLeXA",
        "outputId": "5b62eca9-b246-4402-d194-5ed202ac2aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "parameters = {}\n",
            "\tmean f1 scores: [0.846533790345185, 0.7210437937828895, 0.7433244411583024]\n",
            "\tstd f1 scores: [0.01974246160296447, 0.01936722623622532, 0.009758278023175821]\n",
            "\tmean accuracy: 0.7969752520623281\n",
            "\tstd accuracy: 0.019360189952269062\n"
          ]
        }
      ],
      "source": [
        "show_results(history, report, K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "POzigusNLfLV",
      "metadata": {
        "id": "POzigusNLfLV"
      },
      "outputs": [],
      "source": [
        "save_to_json(history, report, json_path+'/history_gold_int_os.json', json_path+'/report_gold_int_os.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "whRYYesRLgjp",
      "metadata": {
        "id": "whRYYesRLgjp"
      },
      "source": [
        "# Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZR_-oUtVM2Yl",
      "metadata": {
        "id": "ZR_-oUtVM2Yl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UqUGZUUcLh8M",
      "metadata": {
        "id": "UqUGZUUcLh8M"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(Loss):\n",
        "    def __init__(self, gamma=2.0, alpha=None, num_classes=None):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        if num_classes is None:\n",
        "            raise ValueError(\"The 'num_classes' parameter must be specified.\")\n",
        "        if alpha is None:\n",
        "            alpha = [1 for _ in range(num_classes)]\n",
        "        elif len(alpha) != num_classes:\n",
        "            raise ValueError(\"The length of 'alpha' must be equal to 'num_classes'.\")\n",
        "        self.alpha = tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_pred_clip = tf.clip_by_value(y_pred, clip_value_min=1e-4, clip_value_max=1-1e-4)\n",
        "        cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "        entropy = cce(y_true, y_pred)\n",
        "\n",
        "        weight = tf.math.pow(1.0 - y_pred_clip, self.gamma)\n",
        "        focal = tf.reduce_sum(y_true * self.alpha * weight, axis=1)\n",
        "        loss = focal * entropy\n",
        "\n",
        "        return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PhW2s1S0L0nP",
      "metadata": {
        "id": "PhW2s1S0L0nP"
      },
      "outputs": [],
      "source": [
        "# This function receives onehot encoded labels\n",
        "# Give more importance to classes with less amount of samples in the dataset\n",
        "def calculate_weights(y):\n",
        "    y = np.argmax(y, axis=-1) # from onehot to class value (0, 1, 2)\n",
        "    counts = np.unique(y, return_counts=True)[1]\n",
        "    weights = 1 / (counts / len(y)) # inverse of the percentaje of labels per class\n",
        "    sum_weights = np.sum(weights)\n",
        "    return weights / sum_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nh0-4NCwNBVV",
      "metadata": {
        "id": "nh0-4NCwNBVV"
      },
      "outputs": [],
      "source": [
        "def create_build_func(alpha: list[float]):\n",
        "    def build_focal_loss(gamma=1.0):\n",
        "        input_layer = Input(shape=(512, ))\n",
        "\n",
        "        model = Dense(128, activation='relu')(input_layer)\n",
        "        model = Dropout(0.25)(model)\n",
        "        model = Dense(64, activation='relu')(model)\n",
        "        model = Dropout(0.25)(model)\n",
        "\n",
        "        model = Dense(K, activation=\"softmax\")(model)\n",
        "\n",
        "        model = Model(input_layer, model, name=\"VGG16_GOLD_FOCAL_LOSS\")\n",
        "\n",
        "        model.compile(optimizer=\"adam\", loss=FocalLoss(gamma=gamma, alpha=alpha, num_classes=3), metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    return build_focal_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with alpha"
      ],
      "metadata": {
        "id": "o3KxWiBk8X0O"
      },
      "id": "o3KxWiBk8X0O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bH_I-_6rRVxo",
      "metadata": {
        "id": "bH_I-_6rRVxo"
      },
      "outputs": [],
      "source": [
        "X_train, labels, X_test, Y_test = load_gold_data(data_path, pkl_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HeCgd2IMOjpY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeCgd2IMOjpY",
        "outputId": "4d6cc16a-d0b8-438d-dd69-9c31fcfb6f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.01940419 2.71949545 7.29452254]\n",
            "[0.16781628 0.22599518 0.60618853]\n"
          ]
        }
      ],
      "source": [
        "alpha = calculate_weights(labels)\n",
        "print(alpha)\n",
        "build_func = create_build_func(alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TAnbDJjI1Wwn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAnbDJjI1Wwn",
        "outputId": "0a34afeb-6e41-463d-f549-25ecf5003773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished experiments: {(2.0,), (2.5,), (5.0,), (4.0,), (4.5,), (1.0,), (1.5,)}\n",
            "Experiment with parameters: {'gamma': 3.0}\n",
            "Run #1\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 27s 3ms/step - loss: 0.0375 - accuracy: 0.7577 - val_loss: 0.0240 - val_accuracy: 0.8234\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0279 - accuracy: 0.7928 - val_loss: 0.0218 - val_accuracy: 0.8228\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0273 - accuracy: 0.8017 - val_loss: 0.0267 - val_accuracy: 0.8112\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0255 - accuracy: 0.8025 - val_loss: 0.0233 - val_accuracy: 0.7685\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0249 - accuracy: 0.8074 - val_loss: 0.0230 - val_accuracy: 0.8155\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0244 - accuracy: 0.8050 - val_loss: 0.0233 - val_accuracy: 0.7893\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0240 - accuracy: 0.8041 - val_loss: 0.0230 - val_accuracy: 0.8319\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0235 - accuracy: 0.8109 - val_loss: 0.0223 - val_accuracy: 0.8236\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0237 - accuracy: 0.8125 - val_loss: 0.0214 - val_accuracy: 0.8350\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0229 - accuracy: 0.8120 - val_loss: 0.0238 - val_accuracy: 0.8300\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0228 - accuracy: 0.8107 - val_loss: 0.0217 - val_accuracy: 0.8400\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0228 - accuracy: 0.8129 - val_loss: 0.0208 - val_accuracy: 0.8428\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0223 - accuracy: 0.8141 - val_loss: 0.0216 - val_accuracy: 0.8341\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0219 - accuracy: 0.8133 - val_loss: 0.0249 - val_accuracy: 0.8272\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0218 - accuracy: 0.8150 - val_loss: 0.0208 - val_accuracy: 0.8274\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0222 - accuracy: 0.8168 - val_loss: 0.0216 - val_accuracy: 0.8323\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0212 - accuracy: 0.8124 - val_loss: 0.0226 - val_accuracy: 0.7981\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0210 - accuracy: 0.8191 - val_loss: 0.0217 - val_accuracy: 0.8385\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0214 - accuracy: 0.8164 - val_loss: 0.0233 - val_accuracy: 0.8254\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0218 - accuracy: 0.8187 - val_loss: 0.0224 - val_accuracy: 0.8428\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #2\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0412 - accuracy: 0.7569 - val_loss: 0.0241 - val_accuracy: 0.8158\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0286 - accuracy: 0.7931 - val_loss: 0.0229 - val_accuracy: 0.8346\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0264 - accuracy: 0.8014 - val_loss: 0.0227 - val_accuracy: 0.8151\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0253 - accuracy: 0.8049 - val_loss: 0.0235 - val_accuracy: 0.8440\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0247 - accuracy: 0.8048 - val_loss: 0.0234 - val_accuracy: 0.8082\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0248 - accuracy: 0.8045 - val_loss: 0.0224 - val_accuracy: 0.8197\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0239 - accuracy: 0.8076 - val_loss: 0.0207 - val_accuracy: 0.8390\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0234 - accuracy: 0.8106 - val_loss: 0.0221 - val_accuracy: 0.8258\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0238 - accuracy: 0.8063 - val_loss: 0.0278 - val_accuracy: 0.7924\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0229 - accuracy: 0.8087 - val_loss: 0.0216 - val_accuracy: 0.8067\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0225 - accuracy: 0.8108 - val_loss: 0.0222 - val_accuracy: 0.8357\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0227 - accuracy: 0.8100 - val_loss: 0.0210 - val_accuracy: 0.8392\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0223 - accuracy: 0.8098 - val_loss: 0.0209 - val_accuracy: 0.8369\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0219 - accuracy: 0.8102 - val_loss: 0.0220 - val_accuracy: 0.8171\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 32s 4ms/step - loss: 0.0217 - accuracy: 0.8142 - val_loss: 0.0214 - val_accuracy: 0.8262\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0216 - accuracy: 0.8136 - val_loss: 0.0240 - val_accuracy: 0.8396\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0219 - accuracy: 0.8100 - val_loss: 0.0212 - val_accuracy: 0.8185\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0215 - accuracy: 0.8115 - val_loss: 0.0219 - val_accuracy: 0.8415\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0216 - accuracy: 0.8118 - val_loss: 0.0218 - val_accuracy: 0.8319\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0211 - accuracy: 0.8141 - val_loss: 0.0224 - val_accuracy: 0.8314\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #3\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0395 - accuracy: 0.7613 - val_loss: 0.0249 - val_accuracy: 0.8260\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0278 - accuracy: 0.7945 - val_loss: 0.0260 - val_accuracy: 0.8271\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0262 - accuracy: 0.8019 - val_loss: 0.0250 - val_accuracy: 0.8361\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0255 - accuracy: 0.8049 - val_loss: 0.0236 - val_accuracy: 0.8240\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0245 - accuracy: 0.8096 - val_loss: 0.0242 - val_accuracy: 0.8415\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0241 - accuracy: 0.8073 - val_loss: 0.0224 - val_accuracy: 0.8219\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0241 - accuracy: 0.8105 - val_loss: 0.0221 - val_accuracy: 0.8198\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0233 - accuracy: 0.8105 - val_loss: 0.0209 - val_accuracy: 0.8369\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0229 - accuracy: 0.8112 - val_loss: 0.0227 - val_accuracy: 0.8459\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0228 - accuracy: 0.8150 - val_loss: 0.0228 - val_accuracy: 0.8453\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0225 - accuracy: 0.8101 - val_loss: 0.0284 - val_accuracy: 0.7666\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0220 - accuracy: 0.8140 - val_loss: 0.0218 - val_accuracy: 0.8152\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0223 - accuracy: 0.8100 - val_loss: 0.0221 - val_accuracy: 0.8373\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0218 - accuracy: 0.8116 - val_loss: 0.0243 - val_accuracy: 0.8263\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0215 - accuracy: 0.8098 - val_loss: 0.0212 - val_accuracy: 0.8102\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0212 - accuracy: 0.8137 - val_loss: 0.0204 - val_accuracy: 0.8315\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0209 - accuracy: 0.8132 - val_loss: 0.0218 - val_accuracy: 0.8236\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0212 - accuracy: 0.8159 - val_loss: 0.0215 - val_accuracy: 0.7971\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0209 - accuracy: 0.8144 - val_loss: 0.0223 - val_accuracy: 0.8087\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0204 - accuracy: 0.8177 - val_loss: 0.0261 - val_accuracy: 0.7774\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #4\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0392 - accuracy: 0.7569 - val_loss: 0.0246 - val_accuracy: 0.8300\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 32s 4ms/step - loss: 0.0286 - accuracy: 0.7946 - val_loss: 0.0229 - val_accuracy: 0.8299\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0272 - accuracy: 0.8000 - val_loss: 0.0244 - val_accuracy: 0.8100\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0263 - accuracy: 0.8058 - val_loss: 0.0222 - val_accuracy: 0.8259\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0255 - accuracy: 0.8077 - val_loss: 0.0225 - val_accuracy: 0.8063\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0250 - accuracy: 0.8069 - val_loss: 0.0229 - val_accuracy: 0.8154\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0240 - accuracy: 0.8078 - val_loss: 0.0232 - val_accuracy: 0.8106\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0237 - accuracy: 0.8107 - val_loss: 0.0225 - val_accuracy: 0.8450\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0233 - accuracy: 0.8157 - val_loss: 0.0217 - val_accuracy: 0.8162\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0232 - accuracy: 0.8096 - val_loss: 0.0242 - val_accuracy: 0.7826\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0225 - accuracy: 0.8148 - val_loss: 0.0203 - val_accuracy: 0.7953\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0223 - accuracy: 0.8136 - val_loss: 0.0215 - val_accuracy: 0.8264\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0220 - accuracy: 0.8105 - val_loss: 0.0217 - val_accuracy: 0.8355\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0218 - accuracy: 0.8136 - val_loss: 0.0222 - val_accuracy: 0.8066\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0216 - accuracy: 0.8113 - val_loss: 0.0236 - val_accuracy: 0.8299\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0215 - accuracy: 0.8134 - val_loss: 0.0238 - val_accuracy: 0.8221\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0212 - accuracy: 0.8185 - val_loss: 0.0220 - val_accuracy: 0.8011\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0210 - accuracy: 0.8160 - val_loss: 0.0238 - val_accuracy: 0.7333\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0211 - accuracy: 0.8128 - val_loss: 0.0255 - val_accuracy: 0.8122\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0209 - accuracy: 0.8135 - val_loss: 0.0220 - val_accuracy: 0.8236\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #5\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0406 - accuracy: 0.7562 - val_loss: 0.0276 - val_accuracy: 0.8141\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0280 - accuracy: 0.7919 - val_loss: 0.0230 - val_accuracy: 0.8017\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0263 - accuracy: 0.8024 - val_loss: 0.0265 - val_accuracy: 0.7835\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0255 - accuracy: 0.8038 - val_loss: 0.0219 - val_accuracy: 0.8275\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0250 - accuracy: 0.8062 - val_loss: 0.0212 - val_accuracy: 0.8276\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0243 - accuracy: 0.8074 - val_loss: 0.0213 - val_accuracy: 0.8131\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0237 - accuracy: 0.8079 - val_loss: 0.0218 - val_accuracy: 0.8302\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0232 - accuracy: 0.8083 - val_loss: 0.0208 - val_accuracy: 0.8238\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0226 - accuracy: 0.8117 - val_loss: 0.0208 - val_accuracy: 0.8345\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0225 - accuracy: 0.8150 - val_loss: 0.0215 - val_accuracy: 0.8055\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0223 - accuracy: 0.8163 - val_loss: 0.0223 - val_accuracy: 0.8135\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0218 - accuracy: 0.8147 - val_loss: 0.0214 - val_accuracy: 0.8259\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0217 - accuracy: 0.8132 - val_loss: 0.0204 - val_accuracy: 0.8417\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0214 - accuracy: 0.8194 - val_loss: 0.0213 - val_accuracy: 0.8280\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0210 - accuracy: 0.8172 - val_loss: 0.0219 - val_accuracy: 0.8221\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0213 - accuracy: 0.8165 - val_loss: 0.0205 - val_accuracy: 0.8442\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0206 - accuracy: 0.8210 - val_loss: 0.0230 - val_accuracy: 0.8471\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0208 - accuracy: 0.8196 - val_loss: 0.0245 - val_accuracy: 0.8415\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0207 - accuracy: 0.8196 - val_loss: 0.0208 - val_accuracy: 0.8256\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0204 - accuracy: 0.8196 - val_loss: 0.0213 - val_accuracy: 0.8232\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #6\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0403 - accuracy: 0.7512 - val_loss: 0.0230 - val_accuracy: 0.8286\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0280 - accuracy: 0.7957 - val_loss: 0.0226 - val_accuracy: 0.8375\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0262 - accuracy: 0.8047 - val_loss: 0.0216 - val_accuracy: 0.8169\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0253 - accuracy: 0.8090 - val_loss: 0.0215 - val_accuracy: 0.8417\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0243 - accuracy: 0.8125 - val_loss: 0.0224 - val_accuracy: 0.8420\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0242 - accuracy: 0.8133 - val_loss: 0.0236 - val_accuracy: 0.7706\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0231 - accuracy: 0.8111 - val_loss: 0.0218 - val_accuracy: 0.8411\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0226 - accuracy: 0.8144 - val_loss: 0.0218 - val_accuracy: 0.8098\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0227 - accuracy: 0.8163 - val_loss: 0.0202 - val_accuracy: 0.8340\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0224 - accuracy: 0.8162 - val_loss: 0.0222 - val_accuracy: 0.8176\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0222 - accuracy: 0.8136 - val_loss: 0.0203 - val_accuracy: 0.8404\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0219 - accuracy: 0.8128 - val_loss: 0.0221 - val_accuracy: 0.8240\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0218 - accuracy: 0.8148 - val_loss: 0.0210 - val_accuracy: 0.8344\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0217 - accuracy: 0.8158 - val_loss: 0.0208 - val_accuracy: 0.8238\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0211 - accuracy: 0.8164 - val_loss: 0.0206 - val_accuracy: 0.8448\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0214 - accuracy: 0.8155 - val_loss: 0.0231 - val_accuracy: 0.7809\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0210 - accuracy: 0.8203 - val_loss: 0.0220 - val_accuracy: 0.8089\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0210 - accuracy: 0.8154 - val_loss: 0.0217 - val_accuracy: 0.8181\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0210 - accuracy: 0.8206 - val_loss: 0.0208 - val_accuracy: 0.8454\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0204 - accuracy: 0.8173 - val_loss: 0.0225 - val_accuracy: 0.8268\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #7\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 27s 3ms/step - loss: 0.0393 - accuracy: 0.7568 - val_loss: 0.0242 - val_accuracy: 0.8313\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0283 - accuracy: 0.7920 - val_loss: 0.0244 - val_accuracy: 0.8010\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0260 - accuracy: 0.8014 - val_loss: 0.0230 - val_accuracy: 0.8403\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0254 - accuracy: 0.8053 - val_loss: 0.0216 - val_accuracy: 0.8369\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0246 - accuracy: 0.8042 - val_loss: 0.0233 - val_accuracy: 0.8360\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0244 - accuracy: 0.8084 - val_loss: 0.0236 - val_accuracy: 0.7512\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0239 - accuracy: 0.8122 - val_loss: 0.0210 - val_accuracy: 0.8363\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0233 - accuracy: 0.8157 - val_loss: 0.0230 - val_accuracy: 0.8024\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0233 - accuracy: 0.8142 - val_loss: 0.0216 - val_accuracy: 0.8040\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0231 - accuracy: 0.8143 - val_loss: 0.0235 - val_accuracy: 0.8436\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0228 - accuracy: 0.8108 - val_loss: 0.0219 - val_accuracy: 0.8385\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0222 - accuracy: 0.8183 - val_loss: 0.0221 - val_accuracy: 0.8308\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0222 - accuracy: 0.8149 - val_loss: 0.0217 - val_accuracy: 0.8094\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0220 - accuracy: 0.8156 - val_loss: 0.0206 - val_accuracy: 0.8312\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0215 - accuracy: 0.8191 - val_loss: 0.0233 - val_accuracy: 0.8173\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0221 - accuracy: 0.8142 - val_loss: 0.0208 - val_accuracy: 0.8284\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0213 - accuracy: 0.8129 - val_loss: 0.0217 - val_accuracy: 0.8325\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0214 - accuracy: 0.8124 - val_loss: 0.0228 - val_accuracy: 0.8213\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0211 - accuracy: 0.8139 - val_loss: 0.0228 - val_accuracy: 0.8177\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0211 - accuracy: 0.8124 - val_loss: 0.0225 - val_accuracy: 0.8341\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #8\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 27s 3ms/step - loss: 0.0402 - accuracy: 0.7567 - val_loss: 0.0247 - val_accuracy: 0.8245\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0275 - accuracy: 0.7989 - val_loss: 0.0230 - val_accuracy: 0.7917\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0265 - accuracy: 0.8015 - val_loss: 0.0219 - val_accuracy: 0.8213\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0250 - accuracy: 0.8071 - val_loss: 0.0220 - val_accuracy: 0.8047\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0246 - accuracy: 0.8088 - val_loss: 0.0207 - val_accuracy: 0.8265\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0239 - accuracy: 0.8114 - val_loss: 0.0218 - val_accuracy: 0.7921\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0236 - accuracy: 0.8124 - val_loss: 0.0220 - val_accuracy: 0.8206\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0233 - accuracy: 0.8115 - val_loss: 0.0245 - val_accuracy: 0.7835\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0228 - accuracy: 0.8140 - val_loss: 0.0205 - val_accuracy: 0.8456\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0228 - accuracy: 0.8155 - val_loss: 0.0222 - val_accuracy: 0.8442\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0223 - accuracy: 0.8142 - val_loss: 0.0214 - val_accuracy: 0.8460\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0220 - accuracy: 0.8151 - val_loss: 0.0215 - val_accuracy: 0.8086\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0216 - accuracy: 0.8175 - val_loss: 0.0219 - val_accuracy: 0.8276\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0217 - accuracy: 0.8138 - val_loss: 0.0206 - val_accuracy: 0.8314\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0217 - accuracy: 0.8164 - val_loss: 0.0211 - val_accuracy: 0.8310\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0216 - accuracy: 0.8196 - val_loss: 0.0216 - val_accuracy: 0.8209\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0211 - accuracy: 0.8162 - val_loss: 0.0227 - val_accuracy: 0.8290\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0211 - accuracy: 0.8158 - val_loss: 0.0221 - val_accuracy: 0.8227\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0209 - accuracy: 0.8169 - val_loss: 0.0214 - val_accuracy: 0.7789\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0206 - accuracy: 0.8169 - val_loss: 0.0222 - val_accuracy: 0.8275\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #9\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 34s 4ms/step - loss: 0.0407 - accuracy: 0.7519 - val_loss: 0.0247 - val_accuracy: 0.8173\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0281 - accuracy: 0.7917 - val_loss: 0.0228 - val_accuracy: 0.8415\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0265 - accuracy: 0.8010 - val_loss: 0.0249 - val_accuracy: 0.8329\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0258 - accuracy: 0.8048 - val_loss: 0.0223 - val_accuracy: 0.8257\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0248 - accuracy: 0.8105 - val_loss: 0.0250 - val_accuracy: 0.8316\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0246 - accuracy: 0.8106 - val_loss: 0.0218 - val_accuracy: 0.8088\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0239 - accuracy: 0.8140 - val_loss: 0.0215 - val_accuracy: 0.8496\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0239 - accuracy: 0.8118 - val_loss: 0.0223 - val_accuracy: 0.8351\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0231 - accuracy: 0.8115 - val_loss: 0.0215 - val_accuracy: 0.8106\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0235 - accuracy: 0.8122 - val_loss: 0.0214 - val_accuracy: 0.8435\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0228 - accuracy: 0.8120 - val_loss: 0.0210 - val_accuracy: 0.8296\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0227 - accuracy: 0.8170 - val_loss: 0.0210 - val_accuracy: 0.8457\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0221 - accuracy: 0.8173 - val_loss: 0.0222 - val_accuracy: 0.8168\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0220 - accuracy: 0.8155 - val_loss: 0.0211 - val_accuracy: 0.8159\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0218 - accuracy: 0.8177 - val_loss: 0.0228 - val_accuracy: 0.7708\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0219 - accuracy: 0.8148 - val_loss: 0.0231 - val_accuracy: 0.8193\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0214 - accuracy: 0.8146 - val_loss: 0.0234 - val_accuracy: 0.8143\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0212 - accuracy: 0.8169 - val_loss: 0.0213 - val_accuracy: 0.8245\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0212 - accuracy: 0.8164 - val_loss: 0.0235 - val_accuracy: 0.8086\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0210 - accuracy: 0.8171 - val_loss: 0.0232 - val_accuracy: 0.8310\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #10\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 27s 3ms/step - loss: 0.0414 - accuracy: 0.7541 - val_loss: 0.0249 - val_accuracy: 0.8048\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0285 - accuracy: 0.7975 - val_loss: 0.0242 - val_accuracy: 0.8106\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0266 - accuracy: 0.8038 - val_loss: 0.0215 - val_accuracy: 0.8365\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0256 - accuracy: 0.8068 - val_loss: 0.0216 - val_accuracy: 0.8335\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0250 - accuracy: 0.8088 - val_loss: 0.0220 - val_accuracy: 0.8418\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0244 - accuracy: 0.8095 - val_loss: 0.0219 - val_accuracy: 0.8393\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0240 - accuracy: 0.8098 - val_loss: 0.0213 - val_accuracy: 0.8385\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0231 - accuracy: 0.8081 - val_loss: 0.0213 - val_accuracy: 0.8228\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0229 - accuracy: 0.8125 - val_loss: 0.0224 - val_accuracy: 0.8379\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0230 - accuracy: 0.8080 - val_loss: 0.0227 - val_accuracy: 0.7872\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0222 - accuracy: 0.8105 - val_loss: 0.0228 - val_accuracy: 0.8298\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0219 - accuracy: 0.8112 - val_loss: 0.0208 - val_accuracy: 0.8266\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0218 - accuracy: 0.8124 - val_loss: 0.0206 - val_accuracy: 0.8127\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0212 - accuracy: 0.8129 - val_loss: 0.0227 - val_accuracy: 0.8328\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0213 - accuracy: 0.8118 - val_loss: 0.0230 - val_accuracy: 0.8213\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0217 - accuracy: 0.8140 - val_loss: 0.0235 - val_accuracy: 0.8474\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0210 - accuracy: 0.8184 - val_loss: 0.0199 - val_accuracy: 0.8375\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0210 - accuracy: 0.8171 - val_loss: 0.0222 - val_accuracy: 0.8408\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0212 - accuracy: 0.8143 - val_loss: 0.0214 - val_accuracy: 0.8228\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0207 - accuracy: 0.8190 - val_loss: 0.0240 - val_accuracy: 0.8353\n",
            "137/137 [==============================] - 1s 3ms/step\n",
            "Experiment with parameters: {'gamma': 3.5}\n",
            "Run #1\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0372 - accuracy: 0.7450 - val_loss: 0.0256 - val_accuracy: 0.7260\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0230 - accuracy: 0.7854 - val_loss: 0.0177 - val_accuracy: 0.8024\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0216 - accuracy: 0.7975 - val_loss: 0.0191 - val_accuracy: 0.8199\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0209 - accuracy: 0.8034 - val_loss: 0.0171 - val_accuracy: 0.8198\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0199 - accuracy: 0.8082 - val_loss: 0.0175 - val_accuracy: 0.8383\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0197 - accuracy: 0.8044 - val_loss: 0.0189 - val_accuracy: 0.8230\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0195 - accuracy: 0.8058 - val_loss: 0.0178 - val_accuracy: 0.8384\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0192 - accuracy: 0.8080 - val_loss: 0.0164 - val_accuracy: 0.8207\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0182 - accuracy: 0.8108 - val_loss: 0.0177 - val_accuracy: 0.8142\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0183 - accuracy: 0.8093 - val_loss: 0.0168 - val_accuracy: 0.8377\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0183 - accuracy: 0.8113 - val_loss: 0.0213 - val_accuracy: 0.8405\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0179 - accuracy: 0.8052 - val_loss: 0.0174 - val_accuracy: 0.8064\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0177 - accuracy: 0.8070 - val_loss: 0.0161 - val_accuracy: 0.8449\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0178 - accuracy: 0.8093 - val_loss: 0.0190 - val_accuracy: 0.8217\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0174 - accuracy: 0.8081 - val_loss: 0.0188 - val_accuracy: 0.8332\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0174 - accuracy: 0.8115 - val_loss: 0.0171 - val_accuracy: 0.8098\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0171 - accuracy: 0.8087 - val_loss: 0.0166 - val_accuracy: 0.8314\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0173 - accuracy: 0.8077 - val_loss: 0.0175 - val_accuracy: 0.8401\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0171 - accuracy: 0.8071 - val_loss: 0.0190 - val_accuracy: 0.8495\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0167 - accuracy: 0.8093 - val_loss: 0.0180 - val_accuracy: 0.8224\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #2\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0344 - accuracy: 0.7394 - val_loss: 0.0194 - val_accuracy: 0.8316\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0238 - accuracy: 0.7850 - val_loss: 0.0187 - val_accuracy: 0.7983\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0223 - accuracy: 0.7922 - val_loss: 0.0184 - val_accuracy: 0.8331\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0210 - accuracy: 0.7978 - val_loss: 0.0184 - val_accuracy: 0.8362\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0208 - accuracy: 0.7973 - val_loss: 0.0198 - val_accuracy: 0.8193\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0202 - accuracy: 0.7996 - val_loss: 0.0170 - val_accuracy: 0.8328\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0196 - accuracy: 0.8041 - val_loss: 0.0175 - val_accuracy: 0.8205\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0192 - accuracy: 0.8030 - val_loss: 0.0170 - val_accuracy: 0.8292\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0191 - accuracy: 0.8045 - val_loss: 0.0170 - val_accuracy: 0.8302\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0185 - accuracy: 0.8064 - val_loss: 0.0171 - val_accuracy: 0.8267\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0185 - accuracy: 0.8063 - val_loss: 0.0169 - val_accuracy: 0.8327\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0179 - accuracy: 0.8052 - val_loss: 0.0216 - val_accuracy: 0.7756\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0177 - accuracy: 0.8056 - val_loss: 0.0180 - val_accuracy: 0.8412\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0179 - accuracy: 0.8078 - val_loss: 0.0189 - val_accuracy: 0.7802\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0171 - accuracy: 0.8016 - val_loss: 0.0180 - val_accuracy: 0.8080\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0175 - accuracy: 0.8043 - val_loss: 0.0180 - val_accuracy: 0.8050\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0174 - accuracy: 0.8053 - val_loss: 0.0173 - val_accuracy: 0.8128\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0170 - accuracy: 0.8073 - val_loss: 0.0188 - val_accuracy: 0.8389\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0170 - accuracy: 0.8044 - val_loss: 0.0207 - val_accuracy: 0.7458\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0173 - accuracy: 0.8003 - val_loss: 0.0170 - val_accuracy: 0.8322\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #3\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0346 - accuracy: 0.7471 - val_loss: 0.0194 - val_accuracy: 0.8115\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0236 - accuracy: 0.7885 - val_loss: 0.0197 - val_accuracy: 0.8105\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0219 - accuracy: 0.7984 - val_loss: 0.0183 - val_accuracy: 0.8407\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0213 - accuracy: 0.8009 - val_loss: 0.0191 - val_accuracy: 0.8349\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0200 - accuracy: 0.8035 - val_loss: 0.0192 - val_accuracy: 0.8260\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0197 - accuracy: 0.8049 - val_loss: 0.0174 - val_accuracy: 0.8264\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0196 - accuracy: 0.8012 - val_loss: 0.0168 - val_accuracy: 0.8215\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0189 - accuracy: 0.8070 - val_loss: 0.0188 - val_accuracy: 0.8129\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0191 - accuracy: 0.8046 - val_loss: 0.0185 - val_accuracy: 0.8449\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0190 - accuracy: 0.8086 - val_loss: 0.0177 - val_accuracy: 0.8351\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0186 - accuracy: 0.8076 - val_loss: 0.0179 - val_accuracy: 0.8207\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0184 - accuracy: 0.8106 - val_loss: 0.0165 - val_accuracy: 0.8295\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0181 - accuracy: 0.8073 - val_loss: 0.0181 - val_accuracy: 0.7962\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0180 - accuracy: 0.8097 - val_loss: 0.0195 - val_accuracy: 0.8446\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0178 - accuracy: 0.8081 - val_loss: 0.0175 - val_accuracy: 0.8360\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0176 - accuracy: 0.8117 - val_loss: 0.0191 - val_accuracy: 0.8492\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0175 - accuracy: 0.8102 - val_loss: 0.0164 - val_accuracy: 0.8204\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0174 - accuracy: 0.8071 - val_loss: 0.0183 - val_accuracy: 0.8038\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0171 - accuracy: 0.8097 - val_loss: 0.0184 - val_accuracy: 0.7832\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0170 - accuracy: 0.8075 - val_loss: 0.0182 - val_accuracy: 0.8358\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #4\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0331 - accuracy: 0.7493 - val_loss: 0.0188 - val_accuracy: 0.8180\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0226 - accuracy: 0.7925 - val_loss: 0.0199 - val_accuracy: 0.8060\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0211 - accuracy: 0.7983 - val_loss: 0.0187 - val_accuracy: 0.8361\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0208 - accuracy: 0.8036 - val_loss: 0.0191 - val_accuracy: 0.8363\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0202 - accuracy: 0.8068 - val_loss: 0.0178 - val_accuracy: 0.8208\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0194 - accuracy: 0.8056 - val_loss: 0.0172 - val_accuracy: 0.8368\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0190 - accuracy: 0.8076 - val_loss: 0.0171 - val_accuracy: 0.8426\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0190 - accuracy: 0.8078 - val_loss: 0.0179 - val_accuracy: 0.8048\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0184 - accuracy: 0.8104 - val_loss: 0.0175 - val_accuracy: 0.8323\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0181 - accuracy: 0.8058 - val_loss: 0.0171 - val_accuracy: 0.8068\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0180 - accuracy: 0.8058 - val_loss: 0.0180 - val_accuracy: 0.8416\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0180 - accuracy: 0.8089 - val_loss: 0.0167 - val_accuracy: 0.8351\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0174 - accuracy: 0.8078 - val_loss: 0.0171 - val_accuracy: 0.7919\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0175 - accuracy: 0.8094 - val_loss: 0.0174 - val_accuracy: 0.8078\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0174 - accuracy: 0.8104 - val_loss: 0.0161 - val_accuracy: 0.8306\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 33s 4ms/step - loss: 0.0171 - accuracy: 0.8102 - val_loss: 0.0183 - val_accuracy: 0.8218\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 32s 4ms/step - loss: 0.0174 - accuracy: 0.8088 - val_loss: 0.0186 - val_accuracy: 0.8421\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0172 - accuracy: 0.8097 - val_loss: 0.0179 - val_accuracy: 0.7955\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0173 - accuracy: 0.8114 - val_loss: 0.0198 - val_accuracy: 0.8390\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0169 - accuracy: 0.8125 - val_loss: 0.0176 - val_accuracy: 0.8292\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #5\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.0346 - accuracy: 0.7478 - val_loss: 0.0190 - val_accuracy: 0.8203\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0230 - accuracy: 0.7885 - val_loss: 0.0194 - val_accuracy: 0.8104\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0220 - accuracy: 0.7964 - val_loss: 0.0181 - val_accuracy: 0.8246\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0217 - accuracy: 0.7942 - val_loss: 0.0184 - val_accuracy: 0.8175\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0205 - accuracy: 0.7995 - val_loss: 0.0195 - val_accuracy: 0.7141\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0202 - accuracy: 0.8026 - val_loss: 0.0198 - val_accuracy: 0.8234\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0198 - accuracy: 0.8035 - val_loss: 0.0186 - val_accuracy: 0.8300\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0197 - accuracy: 0.8026 - val_loss: 0.0171 - val_accuracy: 0.8225\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0190 - accuracy: 0.8040 - val_loss: 0.0177 - val_accuracy: 0.8397\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0190 - accuracy: 0.8050 - val_loss: 0.0204 - val_accuracy: 0.7978\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0183 - accuracy: 0.8064 - val_loss: 0.0188 - val_accuracy: 0.8278\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0184 - accuracy: 0.8051 - val_loss: 0.0174 - val_accuracy: 0.8228\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0183 - accuracy: 0.8078 - val_loss: 0.0200 - val_accuracy: 0.8144\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0181 - accuracy: 0.8024 - val_loss: 0.0182 - val_accuracy: 0.8343\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0177 - accuracy: 0.8057 - val_loss: 0.0174 - val_accuracy: 0.8102\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0176 - accuracy: 0.8092 - val_loss: 0.0180 - val_accuracy: 0.8243\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0175 - accuracy: 0.8070 - val_loss: 0.0189 - val_accuracy: 0.8315\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0172 - accuracy: 0.8066 - val_loss: 0.0184 - val_accuracy: 0.8149\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0170 - accuracy: 0.8084 - val_loss: 0.0200 - val_accuracy: 0.7866\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0172 - accuracy: 0.8060 - val_loss: 0.0199 - val_accuracy: 0.8267\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #6\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0342 - accuracy: 0.7465 - val_loss: 0.0196 - val_accuracy: 0.8249\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0229 - accuracy: 0.7858 - val_loss: 0.0189 - val_accuracy: 0.8012\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.0216 - accuracy: 0.7976 - val_loss: 0.0178 - val_accuracy: 0.8220\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0211 - accuracy: 0.8022 - val_loss: 0.0169 - val_accuracy: 0.8151\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0200 - accuracy: 0.8044 - val_loss: 0.0181 - val_accuracy: 0.8186\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0201 - accuracy: 0.8059 - val_loss: 0.0183 - val_accuracy: 0.8076\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0193 - accuracy: 0.8076 - val_loss: 0.0172 - val_accuracy: 0.8414\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0189 - accuracy: 0.8126 - val_loss: 0.0176 - val_accuracy: 0.8480\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0191 - accuracy: 0.8109 - val_loss: 0.0168 - val_accuracy: 0.8153\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0183 - accuracy: 0.8094 - val_loss: 0.0176 - val_accuracy: 0.8307\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0186 - accuracy: 0.8088 - val_loss: 0.0167 - val_accuracy: 0.8446\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0183 - accuracy: 0.8080 - val_loss: 0.0184 - val_accuracy: 0.7213\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0178 - accuracy: 0.8112 - val_loss: 0.0174 - val_accuracy: 0.8414\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 32s 4ms/step - loss: 0.0178 - accuracy: 0.8081 - val_loss: 0.0194 - val_accuracy: 0.8403\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0177 - accuracy: 0.8041 - val_loss: 0.0180 - val_accuracy: 0.8335\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0174 - accuracy: 0.8059 - val_loss: 0.0172 - val_accuracy: 0.8389\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0172 - accuracy: 0.8088 - val_loss: 0.0182 - val_accuracy: 0.8172\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0174 - accuracy: 0.8048 - val_loss: 0.0172 - val_accuracy: 0.8164\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0172 - accuracy: 0.8055 - val_loss: 0.0181 - val_accuracy: 0.8196\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0168 - accuracy: 0.8030 - val_loss: 0.0198 - val_accuracy: 0.8278\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #7\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0345 - accuracy: 0.7411 - val_loss: 0.0194 - val_accuracy: 0.8199\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0239 - accuracy: 0.7821 - val_loss: 0.0201 - val_accuracy: 0.8129\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0218 - accuracy: 0.7902 - val_loss: 0.0183 - val_accuracy: 0.8242\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0211 - accuracy: 0.7906 - val_loss: 0.0178 - val_accuracy: 0.7973\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0205 - accuracy: 0.8012 - val_loss: 0.0179 - val_accuracy: 0.8058\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0202 - accuracy: 0.7950 - val_loss: 0.0187 - val_accuracy: 0.7488\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0193 - accuracy: 0.8020 - val_loss: 0.0173 - val_accuracy: 0.8381\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0192 - accuracy: 0.8011 - val_loss: 0.0199 - val_accuracy: 0.7694\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0187 - accuracy: 0.8041 - val_loss: 0.0169 - val_accuracy: 0.8205\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0191 - accuracy: 0.8018 - val_loss: 0.0176 - val_accuracy: 0.8252\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0182 - accuracy: 0.8056 - val_loss: 0.0187 - val_accuracy: 0.8028\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0184 - accuracy: 0.8063 - val_loss: 0.0177 - val_accuracy: 0.7962\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0183 - accuracy: 0.8082 - val_loss: 0.0169 - val_accuracy: 0.8314\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0176 - accuracy: 0.8110 - val_loss: 0.0178 - val_accuracy: 0.8418\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0176 - accuracy: 0.8080 - val_loss: 0.0169 - val_accuracy: 0.8139\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0180 - accuracy: 0.8046 - val_loss: 0.0174 - val_accuracy: 0.8244\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 26s 4ms/step - loss: 0.0175 - accuracy: 0.8033 - val_loss: 0.0168 - val_accuracy: 0.8409\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0174 - accuracy: 0.8100 - val_loss: 0.0176 - val_accuracy: 0.8357\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0170 - accuracy: 0.8066 - val_loss: 0.0178 - val_accuracy: 0.8147\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0171 - accuracy: 0.8062 - val_loss: 0.0181 - val_accuracy: 0.8210\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #8\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0331 - accuracy: 0.7485 - val_loss: 0.0201 - val_accuracy: 0.8281\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0230 - accuracy: 0.7903 - val_loss: 0.0179 - val_accuracy: 0.8365\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0219 - accuracy: 0.7983 - val_loss: 0.0180 - val_accuracy: 0.8226\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0214 - accuracy: 0.8013 - val_loss: 0.0183 - val_accuracy: 0.8155\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0202 - accuracy: 0.8012 - val_loss: 0.0183 - val_accuracy: 0.8369\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0198 - accuracy: 0.8032 - val_loss: 0.0206 - val_accuracy: 0.8209\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0193 - accuracy: 0.8055 - val_loss: 0.0183 - val_accuracy: 0.8003\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0190 - accuracy: 0.8080 - val_loss: 0.0184 - val_accuracy: 0.8160\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0190 - accuracy: 0.8100 - val_loss: 0.0171 - val_accuracy: 0.8329\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0183 - accuracy: 0.8113 - val_loss: 0.0180 - val_accuracy: 0.8356\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0183 - accuracy: 0.8086 - val_loss: 0.0181 - val_accuracy: 0.8392\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.0181 - accuracy: 0.8113 - val_loss: 0.0172 - val_accuracy: 0.8298\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0177 - accuracy: 0.8073 - val_loss: 0.0172 - val_accuracy: 0.8244\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0178 - accuracy: 0.8079 - val_loss: 0.0173 - val_accuracy: 0.8326\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0174 - accuracy: 0.8060 - val_loss: 0.0169 - val_accuracy: 0.8146\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0171 - accuracy: 0.8114 - val_loss: 0.0182 - val_accuracy: 0.8059\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0168 - accuracy: 0.8095 - val_loss: 0.0176 - val_accuracy: 0.8178\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0171 - accuracy: 0.8083 - val_loss: 0.0184 - val_accuracy: 0.8032\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0167 - accuracy: 0.8090 - val_loss: 0.0198 - val_accuracy: 0.7899\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0168 - accuracy: 0.8092 - val_loss: 0.0198 - val_accuracy: 0.8322\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #9\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0349 - accuracy: 0.7485 - val_loss: 0.0211 - val_accuracy: 0.7772\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.0232 - accuracy: 0.7869 - val_loss: 0.0191 - val_accuracy: 0.7884\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0220 - accuracy: 0.7947 - val_loss: 0.0188 - val_accuracy: 0.8322\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0211 - accuracy: 0.8000 - val_loss: 0.0191 - val_accuracy: 0.8157\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0199 - accuracy: 0.8030 - val_loss: 0.0178 - val_accuracy: 0.8420\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0197 - accuracy: 0.8034 - val_loss: 0.0174 - val_accuracy: 0.8258\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0196 - accuracy: 0.8064 - val_loss: 0.0170 - val_accuracy: 0.8338\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0188 - accuracy: 0.8068 - val_loss: 0.0183 - val_accuracy: 0.8401\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0192 - accuracy: 0.8025 - val_loss: 0.0175 - val_accuracy: 0.8278\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0184 - accuracy: 0.8079 - val_loss: 0.0172 - val_accuracy: 0.8252\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 31s 4ms/step - loss: 0.0182 - accuracy: 0.8085 - val_loss: 0.0176 - val_accuracy: 0.8377\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0183 - accuracy: 0.8098 - val_loss: 0.0172 - val_accuracy: 0.8126\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0175 - accuracy: 0.8097 - val_loss: 0.0163 - val_accuracy: 0.8179\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0177 - accuracy: 0.8092 - val_loss: 0.0178 - val_accuracy: 0.8412\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0179 - accuracy: 0.8097 - val_loss: 0.0176 - val_accuracy: 0.8319\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0172 - accuracy: 0.8086 - val_loss: 0.0165 - val_accuracy: 0.8341\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0172 - accuracy: 0.8077 - val_loss: 0.0182 - val_accuracy: 0.7969\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0170 - accuracy: 0.8117 - val_loss: 0.0177 - val_accuracy: 0.8056\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0167 - accuracy: 0.8048 - val_loss: 0.0190 - val_accuracy: 0.8167\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0168 - accuracy: 0.8074 - val_loss: 0.0202 - val_accuracy: 0.8090\n",
            "137/137 [==============================] - 0s 3ms/step\n",
            "Run #10\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 30s 4ms/step - loss: 0.0323 - accuracy: 0.7529 - val_loss: 0.0219 - val_accuracy: 0.7969\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0227 - accuracy: 0.7884 - val_loss: 0.0186 - val_accuracy: 0.8144\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0215 - accuracy: 0.7973 - val_loss: 0.0192 - val_accuracy: 0.7993\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0210 - accuracy: 0.7995 - val_loss: 0.0196 - val_accuracy: 0.7851\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0200 - accuracy: 0.8027 - val_loss: 0.0184 - val_accuracy: 0.8383\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0198 - accuracy: 0.8057 - val_loss: 0.0178 - val_accuracy: 0.8223\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0193 - accuracy: 0.8067 - val_loss: 0.0175 - val_accuracy: 0.8291\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0189 - accuracy: 0.8066 - val_loss: 0.0172 - val_accuracy: 0.8486\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 29s 4ms/step - loss: 0.0186 - accuracy: 0.8053 - val_loss: 0.0171 - val_accuracy: 0.8363\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0187 - accuracy: 0.8078 - val_loss: 0.0168 - val_accuracy: 0.8274\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0184 - accuracy: 0.8041 - val_loss: 0.0187 - val_accuracy: 0.8247\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0180 - accuracy: 0.8046 - val_loss: 0.0179 - val_accuracy: 0.8311\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0174 - accuracy: 0.8071 - val_loss: 0.0183 - val_accuracy: 0.8480\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0171 - accuracy: 0.8091 - val_loss: 0.0181 - val_accuracy: 0.7846\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0174 - accuracy: 0.8067 - val_loss: 0.0180 - val_accuracy: 0.7824\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0171 - accuracy: 0.8109 - val_loss: 0.0180 - val_accuracy: 0.8347\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0171 - accuracy: 0.8096 - val_loss: 0.0163 - val_accuracy: 0.8289\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 28s 4ms/step - loss: 0.0168 - accuracy: 0.8090 - val_loss: 0.0175 - val_accuracy: 0.8256\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0167 - accuracy: 0.8086 - val_loss: 0.0167 - val_accuracy: 0.8050\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0165 - accuracy: 0.8104 - val_loss: 0.0167 - val_accuracy: 0.8222\n",
            "137/137 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "gamma = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
        "history_path = json_path + '/history_gold_int_focal.json'\n",
        "report_path = json_path + '/report_gold_int_focal.json'\n",
        "\n",
        "exp_history, exp_report = grid_search(X_train, labels, X_test, Y_test, build_func,\n",
        "                                      evaluate, repeat=10, epochs=20, validation_split=0.2,\n",
        "                                      report_path=report_path, history_path=history_path, gamma=gamma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73EtQ37lRpFJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73EtQ37lRpFJ",
        "outputId": "a92c81c6-6a74-4787-85c0-9396b08eb3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "parameters = {'gamma': 1.0}\n",
            "\tmean f1 scores: [0.8687050171539287, 0.7461580500611925, 0.7147690149264148]\n",
            "\tstd f1 scores: [0.008768216238164556, 0.012240333849085568, 0.030743370270033044]\n",
            "\tmean accuracy: 0.8154903758020164\n",
            "\tstd accuracy: 0.010204556513752003\n",
            "==================================================\n",
            "parameters = {'gamma': 2.0}\n",
            "\tmean f1 scores: [0.8478464790916937, 0.7178714938254543, 0.6737908918598798]\n",
            "\tstd f1 scores: [0.021187273945552646, 0.01928751877349906, 0.02708217540409559]\n",
            "\tmean accuracy: 0.7886113657195235\n",
            "\tstd accuracy: 0.019248191369869824\n",
            "==================================================\n",
            "parameters = {'gamma': 2.5}\n",
            "\tmean f1 scores: [0.8640302108211818, 0.7372477901785716, 0.7176033730761016]\n",
            "\tstd f1 scores: [0.011349938944466006, 0.017366743272830228, 0.02513559312419964]\n",
            "\tmean accuracy: 0.8105866177818516\n",
            "\tstd accuracy: 0.01180018773227053\n",
            "==================================================\n",
            "parameters = {'gamma': 5.0}\n",
            "\tmean f1 scores: [0.8552799546284946, 0.6998408925554538, 0.6840048712326541]\n",
            "\tstd f1 scores: [0.012469139072146704, 0.050569540947405324, 0.035753939569851116]\n",
            "\tmean accuracy: 0.7923923006416131\n",
            "\tstd accuracy: 0.017571898764670548\n",
            "==================================================\n",
            "parameters = {'gamma': 4.0}\n",
            "\tmean f1 scores: [0.812693137819146, 0.6920579695403639, 0.6763002956591466]\n",
            "\tstd f1 scores: [0.07619757280059984, 0.04208017977484118, 0.05989409571633183]\n",
            "\tmean accuracy: 0.7615261228230981\n",
            "\tstd accuracy: 0.060751947857098844\n",
            "==================================================\n",
            "parameters = {'gamma': 4.5}\n",
            "\tmean f1 scores: [0.8409200744504401, 0.7087029600141442, 0.6852301752345187]\n",
            "\tstd f1 scores: [0.03689305125757967, 0.033675958874714106, 0.02631140074983427]\n",
            "\tmean accuracy: 0.7841888175985334\n",
            "\tstd accuracy: 0.03275332491605776\n",
            "==================================================\n",
            "parameters = {'gamma': 1.5}\n",
            "\tmean f1 scores: [0.8501119269171733, 0.7229151096599259, 0.6904564369003401]\n",
            "\tstd f1 scores: [0.03763752161017781, 0.02766724057169227, 0.02420949554404997]\n",
            "\tmean accuracy: 0.7942254812098992\n",
            "\tstd accuracy: 0.033133344206720004\n",
            "==================================================\n",
            "parameters = {'gamma': 3.0}\n",
            "\tmean f1 scores: [0.8505010343959413, 0.7214966304020498, 0.6972749927248951]\n",
            "\tstd f1 scores: [0.03080430813191397, 0.02627366619300989, 0.027077696384260348]\n",
            "\tmean accuracy: 0.7949129239230064\n",
            "\tstd accuracy: 0.024837102164188496\n",
            "==================================================\n",
            "parameters = {'gamma': 3.5}\n",
            "\tmean f1 scores: [0.8571186313060857, 0.7213536064361575, 0.6899714939270571]\n",
            "\tstd f1 scores: [0.00928180760666667, 0.022449739382614266, 0.02586422946229097]\n",
            "\tmean accuracy: 0.7981897341888177\n",
            "\tstd accuracy: 0.009081907761738561\n"
          ]
        }
      ],
      "source": [
        "show_results(exp_history, exp_report, K)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CcGZkSHXFzg_",
      "metadata": {
        "id": "CcGZkSHXFzg_"
      },
      "source": [
        "### Training without alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "arGB5uXtFq2x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arGB5uXtFq2x",
        "outputId": "32b0b2b5-f8fe-4c0e-9e1c-28c77e235211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiments: {(2.0,), (2.5,), (5.0,), (4.5,), (1.0,), (1.5,), (3.5,), (3.0,)}\n",
            "Experiment with parameters: {'gamma': 4.0}\n",
            "Run #1\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0961 - accuracy: 0.7678 - val_loss: 0.0624 - val_accuracy: 0.8203\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0652 - accuracy: 0.8057 - val_loss: 0.0529 - val_accuracy: 0.8254\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0614 - accuracy: 0.8100 - val_loss: 0.0516 - val_accuracy: 0.8238\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0589 - accuracy: 0.8144 - val_loss: 0.0503 - val_accuracy: 0.8432\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0565 - accuracy: 0.8184 - val_loss: 0.0552 - val_accuracy: 0.8411\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0559 - accuracy: 0.8206 - val_loss: 0.0501 - val_accuracy: 0.8366\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0539 - accuracy: 0.8212 - val_loss: 0.0482 - val_accuracy: 0.8466\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0550 - accuracy: 0.8185 - val_loss: 0.0488 - val_accuracy: 0.8474\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0525 - accuracy: 0.8208 - val_loss: 0.0507 - val_accuracy: 0.8438\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0526 - accuracy: 0.8212 - val_loss: 0.0478 - val_accuracy: 0.8484\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0527 - accuracy: 0.8243 - val_loss: 0.0500 - val_accuracy: 0.8462\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0514 - accuracy: 0.8223 - val_loss: 0.0503 - val_accuracy: 0.8425\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0515 - accuracy: 0.8199 - val_loss: 0.0512 - val_accuracy: 0.8472\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0508 - accuracy: 0.8207 - val_loss: 0.0501 - val_accuracy: 0.8474\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0508 - accuracy: 0.8258 - val_loss: 0.0508 - val_accuracy: 0.8486\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0493 - accuracy: 0.8273 - val_loss: 0.0546 - val_accuracy: 0.7985\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0498 - accuracy: 0.8231 - val_loss: 0.0486 - val_accuracy: 0.8492\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0497 - accuracy: 0.8233 - val_loss: 0.0526 - val_accuracy: 0.8342\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0494 - accuracy: 0.8204 - val_loss: 0.0529 - val_accuracy: 0.8491\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0486 - accuracy: 0.8234 - val_loss: 0.0598 - val_accuracy: 0.8004\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #2\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0947 - accuracy: 0.7693 - val_loss: 0.0640 - val_accuracy: 0.8152\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0653 - accuracy: 0.8032 - val_loss: 0.0551 - val_accuracy: 0.8424\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0621 - accuracy: 0.8087 - val_loss: 0.0511 - val_accuracy: 0.8371\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0598 - accuracy: 0.8143 - val_loss: 0.0497 - val_accuracy: 0.8310\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0582 - accuracy: 0.8145 - val_loss: 0.0538 - val_accuracy: 0.8402\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0576 - accuracy: 0.8181 - val_loss: 0.0497 - val_accuracy: 0.8324\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0561 - accuracy: 0.8187 - val_loss: 0.0471 - val_accuracy: 0.8433\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0545 - accuracy: 0.8202 - val_loss: 0.0543 - val_accuracy: 0.8119\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0540 - accuracy: 0.8209 - val_loss: 0.0505 - val_accuracy: 0.8424\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0534 - accuracy: 0.8216 - val_loss: 0.0507 - val_accuracy: 0.8516\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0522 - accuracy: 0.8248 - val_loss: 0.0510 - val_accuracy: 0.8150\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0532 - accuracy: 0.8255 - val_loss: 0.0490 - val_accuracy: 0.8460\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0517 - accuracy: 0.8225 - val_loss: 0.0477 - val_accuracy: 0.8453\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0509 - accuracy: 0.8245 - val_loss: 0.0482 - val_accuracy: 0.8404\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0508 - accuracy: 0.8256 - val_loss: 0.0488 - val_accuracy: 0.8566\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0502 - accuracy: 0.8227 - val_loss: 0.0493 - val_accuracy: 0.8520\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0499 - accuracy: 0.8234 - val_loss: 0.0488 - val_accuracy: 0.8478\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0496 - accuracy: 0.8253 - val_loss: 0.0524 - val_accuracy: 0.8583\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0500 - accuracy: 0.8241 - val_loss: 0.0557 - val_accuracy: 0.8310\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0487 - accuracy: 0.8265 - val_loss: 0.0526 - val_accuracy: 0.8510\n",
            "137/137 [==============================] - 0s 1ms/step\n",
            "Run #3\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0948 - accuracy: 0.7711 - val_loss: 0.0568 - val_accuracy: 0.8065\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0651 - accuracy: 0.8050 - val_loss: 0.0619 - val_accuracy: 0.8232\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0609 - accuracy: 0.8112 - val_loss: 0.0573 - val_accuracy: 0.8237\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0596 - accuracy: 0.8141 - val_loss: 0.0495 - val_accuracy: 0.8422\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0586 - accuracy: 0.8163 - val_loss: 0.0511 - val_accuracy: 0.8347\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0571 - accuracy: 0.8195 - val_loss: 0.0476 - val_accuracy: 0.8386\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0549 - accuracy: 0.8207 - val_loss: 0.0487 - val_accuracy: 0.8467\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0545 - accuracy: 0.8219 - val_loss: 0.0509 - val_accuracy: 0.8411\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0538 - accuracy: 0.8204 - val_loss: 0.0496 - val_accuracy: 0.8374\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0543 - accuracy: 0.8214 - val_loss: 0.0542 - val_accuracy: 0.8460\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0522 - accuracy: 0.8249 - val_loss: 0.0484 - val_accuracy: 0.8426\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0523 - accuracy: 0.8209 - val_loss: 0.0490 - val_accuracy: 0.8407\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0515 - accuracy: 0.8209 - val_loss: 0.0486 - val_accuracy: 0.8478\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0513 - accuracy: 0.8232 - val_loss: 0.0495 - val_accuracy: 0.8339\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0517 - accuracy: 0.8214 - val_loss: 0.0499 - val_accuracy: 0.8362\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0498 - accuracy: 0.8266 - val_loss: 0.0499 - val_accuracy: 0.8401\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0502 - accuracy: 0.8203 - val_loss: 0.0499 - val_accuracy: 0.8394\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0494 - accuracy: 0.8234 - val_loss: 0.0492 - val_accuracy: 0.8458\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0501 - accuracy: 0.8245 - val_loss: 0.0509 - val_accuracy: 0.8432\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0494 - accuracy: 0.8250 - val_loss: 0.0534 - val_accuracy: 0.8003\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #4\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0973 - accuracy: 0.7645 - val_loss: 0.0571 - val_accuracy: 0.8118\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0658 - accuracy: 0.8035 - val_loss: 0.0540 - val_accuracy: 0.8397\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0610 - accuracy: 0.8092 - val_loss: 0.0527 - val_accuracy: 0.8334\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0598 - accuracy: 0.8112 - val_loss: 0.0517 - val_accuracy: 0.8281\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0578 - accuracy: 0.8160 - val_loss: 0.0482 - val_accuracy: 0.8423\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0568 - accuracy: 0.8157 - val_loss: 0.0555 - val_accuracy: 0.8074\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0552 - accuracy: 0.8167 - val_loss: 0.0510 - val_accuracy: 0.8429\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0549 - accuracy: 0.8180 - val_loss: 0.0512 - val_accuracy: 0.8243\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0537 - accuracy: 0.8191 - val_loss: 0.0576 - val_accuracy: 0.7872\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0534 - accuracy: 0.8222 - val_loss: 0.0480 - val_accuracy: 0.8472\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0521 - accuracy: 0.8245 - val_loss: 0.0500 - val_accuracy: 0.8439\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0520 - accuracy: 0.8217 - val_loss: 0.0518 - val_accuracy: 0.8467\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0518 - accuracy: 0.8214 - val_loss: 0.0503 - val_accuracy: 0.8426\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0504 - accuracy: 0.8226 - val_loss: 0.0486 - val_accuracy: 0.8391\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0511 - accuracy: 0.8215 - val_loss: 0.0512 - val_accuracy: 0.8306\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0505 - accuracy: 0.8229 - val_loss: 0.0497 - val_accuracy: 0.8515\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0502 - accuracy: 0.8250 - val_loss: 0.0570 - val_accuracy: 0.7798\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0492 - accuracy: 0.8201 - val_loss: 0.0501 - val_accuracy: 0.8464\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0496 - accuracy: 0.8209 - val_loss: 0.0535 - val_accuracy: 0.8513\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0489 - accuracy: 0.8228 - val_loss: 0.0521 - val_accuracy: 0.8390\n",
            "137/137 [==============================] - 0s 1ms/step\n",
            "Run #5\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0996 - accuracy: 0.7644 - val_loss: 0.0568 - val_accuracy: 0.8259\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0661 - accuracy: 0.8003 - val_loss: 0.0534 - val_accuracy: 0.8320\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0626 - accuracy: 0.8079 - val_loss: 0.0511 - val_accuracy: 0.8444\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0593 - accuracy: 0.8134 - val_loss: 0.0565 - val_accuracy: 0.8305\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0569 - accuracy: 0.8190 - val_loss: 0.0529 - val_accuracy: 0.8264\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0557 - accuracy: 0.8185 - val_loss: 0.0551 - val_accuracy: 0.7856\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0550 - accuracy: 0.8184 - val_loss: 0.0534 - val_accuracy: 0.8185\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0542 - accuracy: 0.8172 - val_loss: 0.0496 - val_accuracy: 0.8335\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0525 - accuracy: 0.8219 - val_loss: 0.0462 - val_accuracy: 0.8535\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0528 - accuracy: 0.8221 - val_loss: 0.0506 - val_accuracy: 0.8318\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0512 - accuracy: 0.8230 - val_loss: 0.0522 - val_accuracy: 0.8267\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0511 - accuracy: 0.8237 - val_loss: 0.0514 - val_accuracy: 0.8484\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0510 - accuracy: 0.8221 - val_loss: 0.0507 - val_accuracy: 0.8502\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0500 - accuracy: 0.8257 - val_loss: 0.0478 - val_accuracy: 0.8481\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0504 - accuracy: 0.8250 - val_loss: 0.0517 - val_accuracy: 0.8291\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0497 - accuracy: 0.8232 - val_loss: 0.0470 - val_accuracy: 0.8525\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0490 - accuracy: 0.8225 - val_loss: 0.0495 - val_accuracy: 0.8383\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0480 - accuracy: 0.8237 - val_loss: 0.0502 - val_accuracy: 0.8302\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0488 - accuracy: 0.8259 - val_loss: 0.0478 - val_accuracy: 0.8428\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0480 - accuracy: 0.8267 - val_loss: 0.0551 - val_accuracy: 0.8515\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #6\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0972 - accuracy: 0.7642 - val_loss: 0.0541 - val_accuracy: 0.8355\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0657 - accuracy: 0.8033 - val_loss: 0.0546 - val_accuracy: 0.8218\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0618 - accuracy: 0.8112 - val_loss: 0.0491 - val_accuracy: 0.8343\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0595 - accuracy: 0.8155 - val_loss: 0.0497 - val_accuracy: 0.8446\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0575 - accuracy: 0.8170 - val_loss: 0.0483 - val_accuracy: 0.8377\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0564 - accuracy: 0.8183 - val_loss: 0.0488 - val_accuracy: 0.8469\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0555 - accuracy: 0.8190 - val_loss: 0.0484 - val_accuracy: 0.8465\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0550 - accuracy: 0.8187 - val_loss: 0.0489 - val_accuracy: 0.8415\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0544 - accuracy: 0.8198 - val_loss: 0.0521 - val_accuracy: 0.8258\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0539 - accuracy: 0.8193 - val_loss: 0.0480 - val_accuracy: 0.8470\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0527 - accuracy: 0.8189 - val_loss: 0.0476 - val_accuracy: 0.8490\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0537 - accuracy: 0.8185 - val_loss: 0.0471 - val_accuracy: 0.8488\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0525 - accuracy: 0.8228 - val_loss: 0.0509 - val_accuracy: 0.8312\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0512 - accuracy: 0.8248 - val_loss: 0.0483 - val_accuracy: 0.8428\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0520 - accuracy: 0.8224 - val_loss: 0.0498 - val_accuracy: 0.8430\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0499 - accuracy: 0.8256 - val_loss: 0.0490 - val_accuracy: 0.8450\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0511 - accuracy: 0.8220 - val_loss: 0.0513 - val_accuracy: 0.8429\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0508 - accuracy: 0.8202 - val_loss: 0.0504 - val_accuracy: 0.8462\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0499 - accuracy: 0.8240 - val_loss: 0.0514 - val_accuracy: 0.8418\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0498 - accuracy: 0.8240 - val_loss: 0.0507 - val_accuracy: 0.8521\n",
            "137/137 [==============================] - 0s 1ms/step\n",
            "Run #7\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0997 - accuracy: 0.7665 - val_loss: 0.0579 - val_accuracy: 0.8319\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0656 - accuracy: 0.8028 - val_loss: 0.0544 - val_accuracy: 0.8331\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0624 - accuracy: 0.8097 - val_loss: 0.0539 - val_accuracy: 0.8454\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0596 - accuracy: 0.8146 - val_loss: 0.0545 - val_accuracy: 0.8372\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0585 - accuracy: 0.8152 - val_loss: 0.0498 - val_accuracy: 0.8444\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0577 - accuracy: 0.8141 - val_loss: 0.0539 - val_accuracy: 0.8399\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0575 - accuracy: 0.8147 - val_loss: 0.0530 - val_accuracy: 0.8290\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0553 - accuracy: 0.8201 - val_loss: 0.0498 - val_accuracy: 0.8474\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0550 - accuracy: 0.8206 - val_loss: 0.0520 - val_accuracy: 0.8361\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0533 - accuracy: 0.8210 - val_loss: 0.0485 - val_accuracy: 0.8451\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0542 - accuracy: 0.8206 - val_loss: 0.0512 - val_accuracy: 0.8413\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0533 - accuracy: 0.8213 - val_loss: 0.0485 - val_accuracy: 0.8473\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0533 - accuracy: 0.8218 - val_loss: 0.0542 - val_accuracy: 0.8477\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0522 - accuracy: 0.8242 - val_loss: 0.0538 - val_accuracy: 0.8422\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0516 - accuracy: 0.8226 - val_loss: 0.0537 - val_accuracy: 0.7953\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0518 - accuracy: 0.8195 - val_loss: 0.0521 - val_accuracy: 0.8492\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0501 - accuracy: 0.8226 - val_loss: 0.0560 - val_accuracy: 0.7705\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0511 - accuracy: 0.8193 - val_loss: 0.0525 - val_accuracy: 0.8288\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0510 - accuracy: 0.8186 - val_loss: 0.0540 - val_accuracy: 0.8452\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.0504 - accuracy: 0.8209 - val_loss: 0.0496 - val_accuracy: 0.8528\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #8\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.1028 - accuracy: 0.7640 - val_loss: 0.0607 - val_accuracy: 0.8083\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0666 - accuracy: 0.7966 - val_loss: 0.0529 - val_accuracy: 0.8295\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0618 - accuracy: 0.8077 - val_loss: 0.0537 - val_accuracy: 0.8413\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0593 - accuracy: 0.8123 - val_loss: 0.0562 - val_accuracy: 0.8335\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0583 - accuracy: 0.8141 - val_loss: 0.0530 - val_accuracy: 0.8005\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0569 - accuracy: 0.8167 - val_loss: 0.0509 - val_accuracy: 0.8325\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0554 - accuracy: 0.8184 - val_loss: 0.0493 - val_accuracy: 0.8375\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0560 - accuracy: 0.8193 - val_loss: 0.0480 - val_accuracy: 0.8303\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0538 - accuracy: 0.8191 - val_loss: 0.0488 - val_accuracy: 0.8345\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0538 - accuracy: 0.8202 - val_loss: 0.0472 - val_accuracy: 0.8434\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0533 - accuracy: 0.8219 - val_loss: 0.0526 - val_accuracy: 0.8145\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0521 - accuracy: 0.8225 - val_loss: 0.0465 - val_accuracy: 0.8468\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0521 - accuracy: 0.8214 - val_loss: 0.0476 - val_accuracy: 0.8476\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0513 - accuracy: 0.8231 - val_loss: 0.0511 - val_accuracy: 0.8395\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0516 - accuracy: 0.8209 - val_loss: 0.0534 - val_accuracy: 0.8470\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0507 - accuracy: 0.8237 - val_loss: 0.0524 - val_accuracy: 0.8438\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0497 - accuracy: 0.8241 - val_loss: 0.0491 - val_accuracy: 0.8492\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0501 - accuracy: 0.8231 - val_loss: 0.0492 - val_accuracy: 0.8338\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0501 - accuracy: 0.8218 - val_loss: 0.0507 - val_accuracy: 0.8522\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 21s 3ms/step - loss: 0.0494 - accuracy: 0.8229 - val_loss: 0.0469 - val_accuracy: 0.8484\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #9\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 27s 3ms/step - loss: 0.0982 - accuracy: 0.7693 - val_loss: 0.0597 - val_accuracy: 0.8062\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 27s 4ms/step - loss: 0.0653 - accuracy: 0.8022 - val_loss: 0.0556 - val_accuracy: 0.8148\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0619 - accuracy: 0.8073 - val_loss: 0.0542 - val_accuracy: 0.8307\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0596 - accuracy: 0.8136 - val_loss: 0.0532 - val_accuracy: 0.8400\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0575 - accuracy: 0.8158 - val_loss: 0.0493 - val_accuracy: 0.8476\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0573 - accuracy: 0.8183 - val_loss: 0.0516 - val_accuracy: 0.8409\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0556 - accuracy: 0.8204 - val_loss: 0.0476 - val_accuracy: 0.8358\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0552 - accuracy: 0.8205 - val_loss: 0.0532 - val_accuracy: 0.8446\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0544 - accuracy: 0.8198 - val_loss: 0.0518 - val_accuracy: 0.8391\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0530 - accuracy: 0.8193 - val_loss: 0.0505 - val_accuracy: 0.8436\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0532 - accuracy: 0.8234 - val_loss: 0.0475 - val_accuracy: 0.8517\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0513 - accuracy: 0.8227 - val_loss: 0.0538 - val_accuracy: 0.8494\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0512 - accuracy: 0.8235 - val_loss: 0.0553 - val_accuracy: 0.8455\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0509 - accuracy: 0.8239 - val_loss: 0.0494 - val_accuracy: 0.8465\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0507 - accuracy: 0.8239 - val_loss: 0.0500 - val_accuracy: 0.8440\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0509 - accuracy: 0.8224 - val_loss: 0.0479 - val_accuracy: 0.8386\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0495 - accuracy: 0.8251 - val_loss: 0.0498 - val_accuracy: 0.8403\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0491 - accuracy: 0.8241 - val_loss: 0.0513 - val_accuracy: 0.8475\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0487 - accuracy: 0.8247 - val_loss: 0.0545 - val_accuracy: 0.8423\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0481 - accuracy: 0.8259 - val_loss: 0.0516 - val_accuracy: 0.8379\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Run #10\n",
            "Epoch 1/20\n",
            "7525/7525 [==============================] - 26s 3ms/step - loss: 0.1093 - accuracy: 0.7541 - val_loss: 0.0635 - val_accuracy: 0.8174\n",
            "Epoch 2/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0673 - accuracy: 0.7967 - val_loss: 0.0563 - val_accuracy: 0.8280\n",
            "Epoch 3/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0626 - accuracy: 0.8081 - val_loss: 0.0574 - val_accuracy: 0.8178\n",
            "Epoch 4/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0603 - accuracy: 0.8131 - val_loss: 0.0509 - val_accuracy: 0.8368\n",
            "Epoch 5/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0596 - accuracy: 0.8136 - val_loss: 0.0546 - val_accuracy: 0.8243\n",
            "Epoch 6/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0573 - accuracy: 0.8121 - val_loss: 0.0511 - val_accuracy: 0.8375\n",
            "Epoch 7/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0564 - accuracy: 0.8174 - val_loss: 0.0535 - val_accuracy: 0.8381\n",
            "Epoch 8/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0556 - accuracy: 0.8180 - val_loss: 0.0485 - val_accuracy: 0.8379\n",
            "Epoch 9/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0546 - accuracy: 0.8186 - val_loss: 0.0488 - val_accuracy: 0.8331\n",
            "Epoch 10/20\n",
            "7525/7525 [==============================] - 25s 3ms/step - loss: 0.0546 - accuracy: 0.8165 - val_loss: 0.0531 - val_accuracy: 0.8060\n",
            "Epoch 11/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0529 - accuracy: 0.8219 - val_loss: 0.0512 - val_accuracy: 0.8425\n",
            "Epoch 12/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0527 - accuracy: 0.8218 - val_loss: 0.0539 - val_accuracy: 0.8434\n",
            "Epoch 13/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0529 - accuracy: 0.8195 - val_loss: 0.0489 - val_accuracy: 0.8530\n",
            "Epoch 14/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0517 - accuracy: 0.8220 - val_loss: 0.0523 - val_accuracy: 0.8401\n",
            "Epoch 15/20\n",
            "7525/7525 [==============================] - 23s 3ms/step - loss: 0.0513 - accuracy: 0.8209 - val_loss: 0.0517 - val_accuracy: 0.8353\n",
            "Epoch 16/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0513 - accuracy: 0.8224 - val_loss: 0.0514 - val_accuracy: 0.8313\n",
            "Epoch 17/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0498 - accuracy: 0.8220 - val_loss: 0.0509 - val_accuracy: 0.8341\n",
            "Epoch 18/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0493 - accuracy: 0.8243 - val_loss: 0.0528 - val_accuracy: 0.8228\n",
            "Epoch 19/20\n",
            "7525/7525 [==============================] - 22s 3ms/step - loss: 0.0502 - accuracy: 0.8208 - val_loss: 0.0528 - val_accuracy: 0.8242\n",
            "Epoch 20/20\n",
            "7525/7525 [==============================] - 24s 3ms/step - loss: 0.0493 - accuracy: 0.8203 - val_loss: 0.0505 - val_accuracy: 0.8327\n",
            "137/137 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "X_train, labels, X_test, Y_test = load_gold_data(data_path, pkl_path)\n",
        "alpha = [1.0, 1.0, 1.0] # No alpha is the same as multiplying by 1\n",
        "build_func = create_build_func(alpha)\n",
        "\n",
        "gamma = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
        "history_path = json_path + '/history_gold_int_focal_noalpha.json'\n",
        "report_path = json_path + '/report_gold_int_focal_noalpha.json'\n",
        "\n",
        "exp_history, exp_report = grid_search(X_train, labels, X_test, Y_test, build_func,\n",
        "                                      evaluate, repeat=10, epochs=20, validation_split=0.2,\n",
        "                                      report_path=report_path, history_path=history_path, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XfX7Yt8uGgGR",
      "metadata": {
        "id": "XfX7Yt8uGgGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f54a90a-2f67-4b1a-8419-26b806054b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "parameters = {'gamma': 1.0}\n",
            "\tmean f1 scores: [0.8753474631775846, 0.7434290364024903, 0.7450948113211442]\n",
            "\tstd f1 scores: [0.0106320786297854, 0.014868566549473303, 0.026828291410920864]\n",
            "\tmean accuracy: 0.8250229147571035\n",
            "\tstd accuracy: 0.012233218582302178\n",
            "==================================================\n",
            "parameters = {'gamma': 1.5}\n",
            "\tmean f1 scores: [0.8661402658184955, 0.7380392979184387, 0.7369121422472436]\n",
            "\tstd f1 scores: [0.012945628435038655, 0.014402681565793383, 0.03166501728884136]\n",
            "\tmean accuracy: 0.8154445462878094\n",
            "\tstd accuracy: 0.012736647830240746\n",
            "==================================================\n",
            "parameters = {'gamma': 2.0}\n",
            "\tmean f1 scores: [0.876634949440445, 0.7457276327677499, 0.7382895297178378]\n",
            "\tstd f1 scores: [0.009726972586902225, 0.007999524844679987, 0.027066509949472788]\n",
            "\tmean accuracy: 0.8262144821264894\n",
            "\tstd accuracy: 0.008685388217080012\n",
            "==================================================\n",
            "parameters = {'gamma': 2.5}\n",
            "\tmean f1 scores: [0.8705358869161737, 0.7412219171521502, 0.7480781318844205]\n",
            "\tstd f1 scores: [0.009767101784406465, 0.01161696694129031, 0.015407297874718062]\n",
            "\tmean accuracy: 0.8212648945921174\n",
            "\tstd accuracy: 0.01025342565017424\n",
            "==================================================\n",
            "parameters = {'gamma': 5.0}\n",
            "\tmean f1 scores: [0.8585580471359787, 0.7138540595673597, 0.7178498687340652]\n",
            "\tstd f1 scores: [0.02000440942781542, 0.04499478685984163, 0.0391266287241879]\n",
            "\tmean accuracy: 0.8038955087076076\n",
            "\tstd accuracy: 0.021281580261149624\n",
            "==================================================\n",
            "parameters = {'gamma': 3.0}\n",
            "\tmean f1 scores: [0.8682156790057787, 0.7294680063427454, 0.7078921173659345]\n",
            "\tstd f1 scores: [0.017580744445993456, 0.014306594701484217, 0.07069917932844741]\n",
            "\tmean accuracy: 0.813840513290559\n",
            "\tstd accuracy: 0.01740170250993478\n",
            "==================================================\n",
            "parameters = {'gamma': 3.5}\n",
            "\tmean f1 scores: [0.8766163006833725, 0.7260025418306443, 0.7057742967804492]\n",
            "\tstd f1 scores: [0.005857892971724118, 0.017471353812966325, 0.05444488092409175]\n",
            "\tmean accuracy: 0.8198670944087991\n",
            "\tstd accuracy: 0.010193049600523668\n",
            "==================================================\n",
            "parameters = {'gamma': 4.5}\n",
            "\tmean f1 scores: [0.8703601831132011, 0.7328643359098188, 0.7248213212800027]\n",
            "\tstd f1 scores: [0.014489279255846128, 0.01776928172875711, 0.04295726632140593]\n",
            "\tmean accuracy: 0.817461044912924\n",
            "\tstd accuracy: 0.015741687628954965\n",
            "==================================================\n",
            "parameters = {'gamma': 4.0}\n",
            "\tmean f1 scores: [0.8682785914047807, 0.7304941243873277, 0.6922615970916033]\n",
            "\tstd f1 scores: [0.016163366738806754, 0.025971236390834523, 0.05816335587939812]\n",
            "\tmean accuracy: 0.8120531622364803\n",
            "\tstd accuracy: 0.01982299998233841\n"
          ]
        }
      ],
      "source": [
        "show_results(exp_history, exp_report, K)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}